{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f7929e-a342-494e-9362-bbc706cec115",
   "metadata": {},
   "source": [
    "### **Loading Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3c3872-f616-42b8-8926-40b1115cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd9ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.45.1\n"
     ]
    }
   ],
   "source": [
    "from transformers import __version__ as transformers_version\n",
    "print(transformers_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e51aeb-3a46-4756-8053-843190da6d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94147ed3484f41d9ab0b7fab308b4aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26396c-a7d9-48d3-8f4c-4197a7a60b11",
   "metadata": {},
   "source": [
    "# **Finetuning Llama3.2-3B Model on Salesforce/Xlam-function-calling Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15349989-3a33-49c7-981e-22c92d1e4bb9",
   "metadata": {},
   "source": [
    "### **Base Model Inference for JSON Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af32f804-0f65-4148-a8bc-c2e972cd8f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738fbe2f0551458aaad37f201ec5c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '`{\"employee\": {\"name\": \"Jane Smith\", \"designation\": \"Software Engineer\"}}`'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "prompt = 'Convert the following invalid json into valid json in single line: {\"employee\": \"name\": \"Jane Smith\", \"designation\": \"Software Engineer\"}'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, a helpful assistant. Your task is to convert any input into valid json\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb276e7",
   "metadata": {},
   "source": [
    "### **Loading the Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1751cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2acbc21783448ef9691ef48c042c936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4d2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af5389-ca63-4683-a55c-668100c6b0a7",
   "metadata": {},
   "source": [
    "### **Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e98d12-3d4c-4c87-bb47-fd92eab2f9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'query', 'tools', 'id'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Salesforce/xlam-function-calling-60k\",split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02cd400-a339-4f91-908f-b4cc20fd66f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where can I find live giveaways for beta access and games?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"query\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062249cd-2d3a-47d6-b2f6-f3f7d8f89bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"live_giveaways_by_type\", \"arguments\": {\"type\": \"beta\"}}, {\"name\": \"live_giveaways_by_type\", \"arguments\": {\"type\": \"game\"}}]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"answers\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b6aca-2c30-4bea-9bfc-64205b1e46c9",
   "metadata": {},
   "source": [
    "### **Formatting the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ff1452-20a3-4b6a-b28c-6ecd0b475de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_llama_prompt(example):\n",
    "    \"\"\"Format the prompt according to LLaMA 3.2-3B chat template.\"\"\"\n",
    "    prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{example['query']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n{example['answers']}\"\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "dataset = dataset.map(format_llama_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88439d63-0f08-4fca-8cd4-f823bc24fc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'query', 'tools', 'id', 'prompt'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5a8e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\nI need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for \\'ethereum\\'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n[{\"name\": \"web_chain_details\", \"arguments\": {\"chain_slug\": \"ethereum\"}}]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['prompt'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703ade0-315d-4770-b5a3-35198e10cf05",
   "metadata": {},
   "source": [
    "### **Tokenization of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac63bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"prompt\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7cd1f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'query', 'tools', 'id', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "420b1652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'query', 'tools', 'id', 'prompt', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 48000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'query', 'tools', 'id', 'prompt', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ad2e8-ec99-4631-b4bc-f978801345b9",
   "metadata": {},
   "source": [
    "### **Apply Lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39e6481-b204-46cf-bdd9-e9c030a7fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Modules to Fine-Tune: ['v_proj', 'o_proj', 'k_proj', 'q_proj', 'gate_proj', 'down_proj', 'up_proj']\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "# Find all linear module names\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):  # Standard torch.nn.Linear for fine-tuning\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "        if 'lm_head' in lora_module_names:  # Exclude lm_head from fine-tuning\n",
    "            lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "print(\"LoRA Modules to Fine-Tune:\", modules)\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# LoRA configuration for fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],  # Target LoRA modules\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"  # Task type set to Causal Language Modeling\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA for fine-tuning\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958b83db-048d-40e3-93c3-07cf0aae25fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 97255424 | Total: 3310005248 | Percentage: 2.9382%\n"
     ]
    }
   ],
   "source": [
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | Total: {total} | Percentage: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859da30c-827a-464c-9b48-9eb8fb85a171",
   "metadata": {},
   "source": [
    "### **Setting Up Training Arguments and Training for SFTTrainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d00522ef-b7aa-4c24-8380-2ed8de1ab8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geek/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/geek/anaconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/geek/anaconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/home/geek/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441172b9e194431b8f7c762fb45363ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3186, 'grad_norm': 2.166571617126465, 'learning_rate': 0.0001, 'epoch': 0.0}\n",
      "{'loss': 2.5665, 'grad_norm': 0.9053242206573486, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
      "{'loss': 1.7173, 'grad_norm': 1.0338925123214722, 'learning_rate': 0.00019932885906040267, 'epoch': 0.0}\n",
      "{'loss': 1.4843, 'grad_norm': 0.7942467331886292, 'learning_rate': 0.0001986577181208054, 'epoch': 0.0}\n",
      "{'loss': 1.4548, 'grad_norm': 0.7946552634239197, 'learning_rate': 0.00019798657718120806, 'epoch': 0.0}\n",
      "{'loss': 1.2094, 'grad_norm': 0.9228646755218506, 'learning_rate': 0.00019731543624161075, 'epoch': 0.0}\n",
      "{'loss': 1.3435, 'grad_norm': 1.3663142919540405, 'learning_rate': 0.00019664429530201342, 'epoch': 0.0}\n",
      "{'loss': 1.2828, 'grad_norm': 2.510617971420288, 'learning_rate': 0.00019597315436241613, 'epoch': 0.0}\n",
      "{'loss': 1.2173, 'grad_norm': 0.8956913352012634, 'learning_rate': 0.0001953020134228188, 'epoch': 0.0}\n",
      "{'loss': 1.0852, 'grad_norm': 0.8107909560203552, 'learning_rate': 0.0001946308724832215, 'epoch': 0.0}\n",
      "{'loss': 1.1321, 'grad_norm': 0.829254150390625, 'learning_rate': 0.00019395973154362416, 'epoch': 0.0}\n",
      "{'loss': 0.9216, 'grad_norm': 1.0441255569458008, 'learning_rate': 0.00019328859060402688, 'epoch': 0.01}\n",
      "{'loss': 1.0374, 'grad_norm': 0.9958419799804688, 'learning_rate': 0.00019261744966442954, 'epoch': 0.01}\n",
      "{'loss': 1.1256, 'grad_norm': 0.5516207814216614, 'learning_rate': 0.0001919463087248322, 'epoch': 0.01}\n",
      "{'loss': 0.9244, 'grad_norm': 0.6405746340751648, 'learning_rate': 0.0001912751677852349, 'epoch': 0.01}\n",
      "{'loss': 1.0756, 'grad_norm': 0.5376086235046387, 'learning_rate': 0.0001906040268456376, 'epoch': 0.01}\n",
      "{'loss': 0.9994, 'grad_norm': 0.5429980158805847, 'learning_rate': 0.00018993288590604028, 'epoch': 0.01}\n",
      "{'loss': 1.1674, 'grad_norm': 0.5203306674957275, 'learning_rate': 0.00018926174496644295, 'epoch': 0.01}\n",
      "{'loss': 1.0762, 'grad_norm': 0.6011402606964111, 'learning_rate': 0.00018859060402684564, 'epoch': 0.01}\n",
      "{'loss': 1.0092, 'grad_norm': 0.4712623953819275, 'learning_rate': 0.00018791946308724833, 'epoch': 0.01}\n",
      "{'loss': 0.984, 'grad_norm': 0.41394445300102234, 'learning_rate': 0.00018724832214765102, 'epoch': 0.01}\n",
      "{'loss': 1.1555, 'grad_norm': 0.6283858418464661, 'learning_rate': 0.0001865771812080537, 'epoch': 0.01}\n",
      "{'loss': 1.1694, 'grad_norm': 0.4653840959072113, 'learning_rate': 0.00018590604026845638, 'epoch': 0.01}\n",
      "{'loss': 0.8581, 'grad_norm': 0.6545945405960083, 'learning_rate': 0.00018523489932885907, 'epoch': 0.01}\n",
      "{'loss': 1.0833, 'grad_norm': 0.5979922413825989, 'learning_rate': 0.00018456375838926174, 'epoch': 0.01}\n",
      "{'loss': 0.9188, 'grad_norm': 0.6850301623344421, 'learning_rate': 0.00018389261744966443, 'epoch': 0.01}\n",
      "{'loss': 1.0431, 'grad_norm': 0.7496387362480164, 'learning_rate': 0.00018322147651006712, 'epoch': 0.01}\n",
      "{'loss': 0.7959, 'grad_norm': 0.42050042748451233, 'learning_rate': 0.00018255033557046981, 'epoch': 0.01}\n",
      "{'loss': 1.0572, 'grad_norm': 0.6357945203781128, 'learning_rate': 0.00018187919463087248, 'epoch': 0.01}\n",
      "{'loss': 1.1167, 'grad_norm': 0.8211695551872253, 'learning_rate': 0.00018120805369127517, 'epoch': 0.01}\n",
      "{'loss': 0.9551, 'grad_norm': 0.4808894693851471, 'learning_rate': 0.00018053691275167786, 'epoch': 0.01}\n",
      "{'loss': 1.0039, 'grad_norm': 0.433271199464798, 'learning_rate': 0.00017986577181208056, 'epoch': 0.01}\n",
      "{'loss': 0.9407, 'grad_norm': 0.6321374177932739, 'learning_rate': 0.00017919463087248322, 'epoch': 0.01}\n",
      "{'loss': 1.0037, 'grad_norm': 0.5487589836120605, 'learning_rate': 0.0001785234899328859, 'epoch': 0.01}\n",
      "{'loss': 1.017, 'grad_norm': 0.5793922543525696, 'learning_rate': 0.0001778523489932886, 'epoch': 0.01}\n",
      "{'loss': 0.9788, 'grad_norm': 0.5927325487136841, 'learning_rate': 0.0001771812080536913, 'epoch': 0.01}\n",
      "{'loss': 1.0345, 'grad_norm': 0.465545117855072, 'learning_rate': 0.00017651006711409396, 'epoch': 0.02}\n",
      "{'loss': 0.9594, 'grad_norm': 0.4945431351661682, 'learning_rate': 0.00017583892617449665, 'epoch': 0.02}\n",
      "{'loss': 1.0063, 'grad_norm': 0.43652626872062683, 'learning_rate': 0.00017516778523489935, 'epoch': 0.02}\n",
      "{'loss': 0.9047, 'grad_norm': 0.7234870195388794, 'learning_rate': 0.000174496644295302, 'epoch': 0.02}\n",
      "{'loss': 1.0618, 'grad_norm': 0.5972083806991577, 'learning_rate': 0.0001738255033557047, 'epoch': 0.02}\n",
      "{'loss': 0.9002, 'grad_norm': 0.4703346788883209, 'learning_rate': 0.0001731543624161074, 'epoch': 0.02}\n",
      "{'loss': 0.9474, 'grad_norm': 0.5871809124946594, 'learning_rate': 0.0001724832214765101, 'epoch': 0.02}\n",
      "{'loss': 0.9865, 'grad_norm': 0.6363784670829773, 'learning_rate': 0.00017181208053691275, 'epoch': 0.02}\n",
      "{'loss': 0.9285, 'grad_norm': 0.45880842208862305, 'learning_rate': 0.00017114093959731544, 'epoch': 0.02}\n",
      "{'loss': 1.0427, 'grad_norm': 0.5638921856880188, 'learning_rate': 0.00017046979865771814, 'epoch': 0.02}\n",
      "{'loss': 1.0022, 'grad_norm': 0.8510433435440063, 'learning_rate': 0.00016979865771812083, 'epoch': 0.02}\n",
      "{'loss': 0.9972, 'grad_norm': 0.6316676735877991, 'learning_rate': 0.0001691275167785235, 'epoch': 0.02}\n",
      "{'loss': 0.8579, 'grad_norm': 0.5156789422035217, 'learning_rate': 0.00016845637583892619, 'epoch': 0.02}\n",
      "{'loss': 1.0083, 'grad_norm': 0.5704814791679382, 'learning_rate': 0.00016778523489932888, 'epoch': 0.02}\n",
      "{'loss': 0.9772, 'grad_norm': 0.5681270360946655, 'learning_rate': 0.00016711409395973154, 'epoch': 0.02}\n",
      "{'loss': 1.073, 'grad_norm': 0.5784369111061096, 'learning_rate': 0.00016644295302013423, 'epoch': 0.02}\n",
      "{'loss': 1.077, 'grad_norm': 0.5377407073974609, 'learning_rate': 0.00016577181208053693, 'epoch': 0.02}\n",
      "{'loss': 1.0386, 'grad_norm': 0.6239113211631775, 'learning_rate': 0.00016510067114093962, 'epoch': 0.02}\n",
      "{'loss': 0.7872, 'grad_norm': 0.7321817874908447, 'learning_rate': 0.00016442953020134228, 'epoch': 0.02}\n",
      "{'loss': 1.0517, 'grad_norm': 0.504960834980011, 'learning_rate': 0.00016375838926174498, 'epoch': 0.02}\n",
      "{'loss': 1.0411, 'grad_norm': 0.5616984963417053, 'learning_rate': 0.00016308724832214767, 'epoch': 0.02}\n",
      "{'loss': 0.9612, 'grad_norm': 0.5755542516708374, 'learning_rate': 0.00016241610738255036, 'epoch': 0.02}\n",
      "{'loss': 0.7723, 'grad_norm': 0.42718306183815, 'learning_rate': 0.00016174496644295302, 'epoch': 0.02}\n",
      "{'loss': 0.9283, 'grad_norm': 0.573813259601593, 'learning_rate': 0.0001610738255033557, 'epoch': 0.03}\n",
      "{'loss': 0.8209, 'grad_norm': 0.5039804577827454, 'learning_rate': 0.0001604026845637584, 'epoch': 0.03}\n",
      "{'loss': 0.8816, 'grad_norm': 0.47845983505249023, 'learning_rate': 0.00015973154362416107, 'epoch': 0.03}\n",
      "{'loss': 1.1711, 'grad_norm': 0.38997185230255127, 'learning_rate': 0.00015906040268456377, 'epoch': 0.03}\n",
      "{'loss': 0.8834, 'grad_norm': 0.4562310576438904, 'learning_rate': 0.00015838926174496643, 'epoch': 0.03}\n",
      "{'loss': 0.8251, 'grad_norm': 0.44213131070137024, 'learning_rate': 0.00015771812080536915, 'epoch': 0.03}\n",
      "{'loss': 0.8358, 'grad_norm': 0.4872726500034332, 'learning_rate': 0.00015704697986577181, 'epoch': 0.03}\n",
      "{'loss': 0.8845, 'grad_norm': 0.5090832114219666, 'learning_rate': 0.0001563758389261745, 'epoch': 0.03}\n",
      "{'loss': 0.7988, 'grad_norm': 0.40954598784446716, 'learning_rate': 0.0001557046979865772, 'epoch': 0.03}\n",
      "{'loss': 0.9671, 'grad_norm': 0.4781828820705414, 'learning_rate': 0.0001550335570469799, 'epoch': 0.03}\n",
      "{'loss': 0.7815, 'grad_norm': 0.5409976840019226, 'learning_rate': 0.00015436241610738256, 'epoch': 0.03}\n",
      "{'loss': 0.923, 'grad_norm': 0.550574541091919, 'learning_rate': 0.00015369127516778522, 'epoch': 0.03}\n",
      "{'loss': 0.9472, 'grad_norm': 0.4636877775192261, 'learning_rate': 0.00015302013422818794, 'epoch': 0.03}\n",
      "{'loss': 0.8653, 'grad_norm': 0.4454346299171448, 'learning_rate': 0.0001523489932885906, 'epoch': 0.03}\n",
      "{'loss': 1.0129, 'grad_norm': 0.5514316558837891, 'learning_rate': 0.0001516778523489933, 'epoch': 0.03}\n",
      "{'loss': 0.8566, 'grad_norm': 0.3933401107788086, 'learning_rate': 0.00015100671140939596, 'epoch': 0.03}\n",
      "{'loss': 0.9529, 'grad_norm': 0.6641344428062439, 'learning_rate': 0.00015033557046979868, 'epoch': 0.03}\n",
      "{'loss': 0.8137, 'grad_norm': 0.5649786591529846, 'learning_rate': 0.00014966442953020135, 'epoch': 0.03}\n",
      "{'loss': 0.9976, 'grad_norm': 0.7586888074874878, 'learning_rate': 0.00014899328859060404, 'epoch': 0.03}\n",
      "{'loss': 0.8757, 'grad_norm': 0.5873548984527588, 'learning_rate': 0.0001483221476510067, 'epoch': 0.03}\n",
      "{'loss': 1.0648, 'grad_norm': 0.4802497625350952, 'learning_rate': 0.00014765100671140942, 'epoch': 0.03}\n",
      "{'loss': 0.8318, 'grad_norm': 0.533436119556427, 'learning_rate': 0.0001469798657718121, 'epoch': 0.03}\n",
      "{'loss': 0.9415, 'grad_norm': 0.47768014669418335, 'learning_rate': 0.00014630872483221478, 'epoch': 0.03}\n",
      "{'loss': 0.8917, 'grad_norm': 0.5774816274642944, 'learning_rate': 0.00014563758389261744, 'epoch': 0.03}\n",
      "{'loss': 0.9278, 'grad_norm': 0.8016126155853271, 'learning_rate': 0.00014496644295302014, 'epoch': 0.04}\n",
      "{'loss': 0.8199, 'grad_norm': 0.4877779185771942, 'learning_rate': 0.00014429530201342283, 'epoch': 0.04}\n",
      "{'loss': 0.8696, 'grad_norm': 0.451567143201828, 'learning_rate': 0.0001436241610738255, 'epoch': 0.04}\n",
      "{'loss': 0.8753, 'grad_norm': 0.444227010011673, 'learning_rate': 0.00014295302013422819, 'epoch': 0.04}\n",
      "{'loss': 1.0365, 'grad_norm': 0.3783300220966339, 'learning_rate': 0.00014228187919463088, 'epoch': 0.04}\n",
      "{'loss': 0.8852, 'grad_norm': 0.4393952786922455, 'learning_rate': 0.00014161073825503357, 'epoch': 0.04}\n",
      "{'loss': 0.9017, 'grad_norm': 0.4547188878059387, 'learning_rate': 0.00014093959731543624, 'epoch': 0.04}\n",
      "{'loss': 0.7734, 'grad_norm': 0.41175493597984314, 'learning_rate': 0.00014026845637583895, 'epoch': 0.04}\n",
      "{'loss': 0.8521, 'grad_norm': 0.5580703020095825, 'learning_rate': 0.00013959731543624162, 'epoch': 0.04}\n",
      "{'loss': 0.9848, 'grad_norm': 0.47898656129837036, 'learning_rate': 0.0001389261744966443, 'epoch': 0.04}\n",
      "{'loss': 0.8913, 'grad_norm': 0.4540195167064667, 'learning_rate': 0.00013825503355704698, 'epoch': 0.04}\n",
      "{'loss': 0.8999, 'grad_norm': 0.5627437233924866, 'learning_rate': 0.00013758389261744967, 'epoch': 0.04}\n",
      "{'loss': 0.9961, 'grad_norm': 0.6434364318847656, 'learning_rate': 0.00013691275167785236, 'epoch': 0.04}\n",
      "{'loss': 0.8859, 'grad_norm': 0.5993156433105469, 'learning_rate': 0.00013624161073825503, 'epoch': 0.04}\n",
      "{'loss': 0.9038, 'grad_norm': 0.4800977110862732, 'learning_rate': 0.00013557046979865772, 'epoch': 0.04}\n",
      "{'loss': 0.7184, 'grad_norm': 0.40693631768226624, 'learning_rate': 0.0001348993288590604, 'epoch': 0.04}\n",
      "{'loss': 1.1155, 'grad_norm': 0.9232099652290344, 'learning_rate': 0.0001342281879194631, 'epoch': 0.04}\n",
      "{'loss': 0.8044, 'grad_norm': 0.4243148863315582, 'learning_rate': 0.00013355704697986577, 'epoch': 0.04}\n",
      "{'loss': 0.8524, 'grad_norm': 0.3917699158191681, 'learning_rate': 0.00013288590604026846, 'epoch': 0.04}\n",
      "{'loss': 0.7846, 'grad_norm': 0.4666896462440491, 'learning_rate': 0.00013221476510067115, 'epoch': 0.04}\n",
      "{'loss': 0.8179, 'grad_norm': 0.5354128479957581, 'learning_rate': 0.00013154362416107384, 'epoch': 0.04}\n",
      "{'loss': 0.8686, 'grad_norm': 0.6519604325294495, 'learning_rate': 0.0001308724832214765, 'epoch': 0.04}\n",
      "{'loss': 0.7697, 'grad_norm': 0.41175487637519836, 'learning_rate': 0.0001302013422818792, 'epoch': 0.04}\n",
      "{'loss': 0.8418, 'grad_norm': 0.36186930537223816, 'learning_rate': 0.0001295302013422819, 'epoch': 0.04}\n",
      "{'loss': 0.9103, 'grad_norm': 0.5965428352355957, 'learning_rate': 0.00012885906040268456, 'epoch': 0.04}\n",
      "{'loss': 0.8313, 'grad_norm': 0.6593118906021118, 'learning_rate': 0.00012818791946308725, 'epoch': 0.05}\n",
      "{'loss': 0.7395, 'grad_norm': 0.5788364410400391, 'learning_rate': 0.00012751677852348994, 'epoch': 0.05}\n",
      "{'loss': 0.9386, 'grad_norm': 0.43552377820014954, 'learning_rate': 0.00012684563758389263, 'epoch': 0.05}\n",
      "{'loss': 0.8891, 'grad_norm': 0.4437605142593384, 'learning_rate': 0.0001261744966442953, 'epoch': 0.05}\n",
      "{'loss': 0.7473, 'grad_norm': 0.4492478668689728, 'learning_rate': 0.000125503355704698, 'epoch': 0.05}\n",
      "{'loss': 0.9663, 'grad_norm': 0.5343290567398071, 'learning_rate': 0.00012483221476510068, 'epoch': 0.05}\n",
      "{'loss': 0.7299, 'grad_norm': 0.40255674719810486, 'learning_rate': 0.00012416107382550337, 'epoch': 0.05}\n",
      "{'loss': 0.8628, 'grad_norm': 0.4389103651046753, 'learning_rate': 0.00012348993288590604, 'epoch': 0.05}\n",
      "{'loss': 0.6987, 'grad_norm': 0.3849937915802002, 'learning_rate': 0.00012281879194630873, 'epoch': 0.05}\n",
      "{'loss': 0.8868, 'grad_norm': 0.42447227239608765, 'learning_rate': 0.00012214765100671142, 'epoch': 0.05}\n",
      "{'loss': 0.8665, 'grad_norm': 0.7642379403114319, 'learning_rate': 0.00012147651006711409, 'epoch': 0.05}\n",
      "{'loss': 0.7498, 'grad_norm': 0.5640616416931152, 'learning_rate': 0.0001208053691275168, 'epoch': 0.05}\n",
      "{'loss': 0.8253, 'grad_norm': 0.47642266750335693, 'learning_rate': 0.00012013422818791946, 'epoch': 0.05}\n",
      "{'loss': 0.8687, 'grad_norm': 0.5583912134170532, 'learning_rate': 0.00011946308724832216, 'epoch': 0.05}\n",
      "{'loss': 0.8032, 'grad_norm': 0.3510036766529083, 'learning_rate': 0.00011879194630872483, 'epoch': 0.05}\n",
      "{'loss': 0.9269, 'grad_norm': 0.46697765588760376, 'learning_rate': 0.00011812080536912754, 'epoch': 0.05}\n",
      "{'loss': 0.8587, 'grad_norm': 0.6581798791885376, 'learning_rate': 0.0001174496644295302, 'epoch': 0.05}\n",
      "{'loss': 0.9245, 'grad_norm': 0.49570563435554504, 'learning_rate': 0.0001167785234899329, 'epoch': 0.05}\n",
      "{'loss': 1.0037, 'grad_norm': 0.5020163059234619, 'learning_rate': 0.00011610738255033557, 'epoch': 0.05}\n",
      "{'loss': 0.7416, 'grad_norm': 0.49418905377388, 'learning_rate': 0.00011543624161073828, 'epoch': 0.05}\n",
      "{'loss': 0.7116, 'grad_norm': 0.5871843695640564, 'learning_rate': 0.00011476510067114094, 'epoch': 0.05}\n",
      "{'loss': 0.8429, 'grad_norm': 0.3581569194793701, 'learning_rate': 0.00011409395973154362, 'epoch': 0.05}\n",
      "{'loss': 0.8806, 'grad_norm': 0.48713892698287964, 'learning_rate': 0.00011342281879194631, 'epoch': 0.05}\n",
      "{'loss': 0.7716, 'grad_norm': 0.6087223887443542, 'learning_rate': 0.00011275167785234899, 'epoch': 0.06}\n",
      "{'loss': 0.7304, 'grad_norm': 0.4256153702735901, 'learning_rate': 0.00011208053691275168, 'epoch': 0.06}\n",
      "{'loss': 0.9212, 'grad_norm': 0.5931227803230286, 'learning_rate': 0.00011140939597315436, 'epoch': 0.06}\n",
      "{'loss': 0.6639, 'grad_norm': 0.3011372685432434, 'learning_rate': 0.00011073825503355705, 'epoch': 0.06}\n",
      "{'loss': 1.0677, 'grad_norm': 0.5843605399131775, 'learning_rate': 0.00011006711409395973, 'epoch': 0.06}\n",
      "{'loss': 0.9026, 'grad_norm': 0.4117451012134552, 'learning_rate': 0.00010939597315436242, 'epoch': 0.06}\n",
      "{'loss': 0.8797, 'grad_norm': 0.5844732522964478, 'learning_rate': 0.0001087248322147651, 'epoch': 0.06}\n",
      "{'loss': 1.0083, 'grad_norm': 0.6144633293151855, 'learning_rate': 0.0001080536912751678, 'epoch': 0.06}\n",
      "{'loss': 0.8744, 'grad_norm': 0.5501827597618103, 'learning_rate': 0.00010738255033557047, 'epoch': 0.06}\n",
      "{'loss': 0.9749, 'grad_norm': 0.48225802183151245, 'learning_rate': 0.00010671140939597315, 'epoch': 0.06}\n",
      "{'loss': 0.7912, 'grad_norm': 0.3703574538230896, 'learning_rate': 0.00010604026845637584, 'epoch': 0.06}\n",
      "{'loss': 0.8268, 'grad_norm': 0.44683483242988586, 'learning_rate': 0.00010536912751677852, 'epoch': 0.06}\n",
      "{'loss': 0.6969, 'grad_norm': 0.49443522095680237, 'learning_rate': 0.00010469798657718121, 'epoch': 0.06}\n",
      "{'loss': 0.7806, 'grad_norm': 0.5204131007194519, 'learning_rate': 0.00010402684563758389, 'epoch': 0.06}\n",
      "{'loss': 0.7891, 'grad_norm': 0.5317012667655945, 'learning_rate': 0.00010335570469798659, 'epoch': 0.06}\n",
      "{'loss': 0.8253, 'grad_norm': 0.5097464919090271, 'learning_rate': 0.00010268456375838926, 'epoch': 0.06}\n",
      "{'loss': 0.8643, 'grad_norm': 0.5585388541221619, 'learning_rate': 0.00010201342281879196, 'epoch': 0.06}\n",
      "{'loss': 0.7675, 'grad_norm': 0.4857460558414459, 'learning_rate': 0.00010134228187919463, 'epoch': 0.06}\n",
      "{'loss': 0.9952, 'grad_norm': 0.4271698594093323, 'learning_rate': 0.00010067114093959733, 'epoch': 0.06}\n",
      "{'loss': 0.8258, 'grad_norm': 0.5378246307373047, 'learning_rate': 0.0001, 'epoch': 0.06}\n",
      "{'loss': 0.8032, 'grad_norm': 0.4929530620574951, 'learning_rate': 9.93288590604027e-05, 'epoch': 0.06}\n",
      "{'loss': 0.793, 'grad_norm': 0.385857492685318, 'learning_rate': 9.865771812080538e-05, 'epoch': 0.06}\n",
      "{'loss': 0.774, 'grad_norm': 0.4821471869945526, 'learning_rate': 9.798657718120807e-05, 'epoch': 0.06}\n",
      "{'loss': 0.898, 'grad_norm': 0.9033327102661133, 'learning_rate': 9.731543624161075e-05, 'epoch': 0.06}\n",
      "{'loss': 0.8234, 'grad_norm': 0.6425274014472961, 'learning_rate': 9.664429530201344e-05, 'epoch': 0.07}\n",
      "{'loss': 0.91, 'grad_norm': 0.4302319586277008, 'learning_rate': 9.59731543624161e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6105, 'grad_norm': 0.4348638653755188, 'learning_rate': 9.53020134228188e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8759, 'grad_norm': 0.6010864973068237, 'learning_rate': 9.463087248322147e-05, 'epoch': 0.07}\n",
      "{'loss': 0.76, 'grad_norm': 0.51827073097229, 'learning_rate': 9.395973154362417e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9125, 'grad_norm': 0.45581763982772827, 'learning_rate': 9.328859060402684e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8404, 'grad_norm': 0.4489261507987976, 'learning_rate': 9.261744966442954e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8365, 'grad_norm': 0.48099225759506226, 'learning_rate': 9.194630872483221e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7065, 'grad_norm': 0.4109680950641632, 'learning_rate': 9.127516778523491e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9006, 'grad_norm': 0.4606034457683563, 'learning_rate': 9.060402684563759e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8115, 'grad_norm': 0.5131140351295471, 'learning_rate': 8.993288590604028e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9406, 'grad_norm': 0.5830276012420654, 'learning_rate': 8.926174496644296e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9083, 'grad_norm': 0.535480797290802, 'learning_rate': 8.859060402684565e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7452, 'grad_norm': 0.6799635291099548, 'learning_rate': 8.791946308724833e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9202, 'grad_norm': 0.39350050687789917, 'learning_rate': 8.7248322147651e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7976, 'grad_norm': 0.5382634401321411, 'learning_rate': 8.65771812080537e-05, 'epoch': 0.07}\n",
      "{'loss': 0.807, 'grad_norm': 0.5988098382949829, 'learning_rate': 8.590604026845638e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8154, 'grad_norm': 0.5260782837867737, 'learning_rate': 8.523489932885907e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8176, 'grad_norm': 0.5526793599128723, 'learning_rate': 8.456375838926175e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8663, 'grad_norm': 0.5612318515777588, 'learning_rate': 8.389261744966444e-05, 'epoch': 0.07}\n",
      "{'loss': 0.869, 'grad_norm': 0.41855111718177795, 'learning_rate': 8.322147651006712e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7721, 'grad_norm': 0.37517431378364563, 'learning_rate': 8.255033557046981e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7482, 'grad_norm': 0.49124225974082947, 'learning_rate': 8.187919463087249e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7481, 'grad_norm': 0.41116783022880554, 'learning_rate': 8.120805369127518e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8106, 'grad_norm': 0.5905811190605164, 'learning_rate': 8.053691275167784e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9063, 'grad_norm': 0.3856705129146576, 'learning_rate': 7.986577181208054e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7501, 'grad_norm': 0.423433780670166, 'learning_rate': 7.919463087248322e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8264, 'grad_norm': 0.5002030730247498, 'learning_rate': 7.852348993288591e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8556, 'grad_norm': 0.41456878185272217, 'learning_rate': 7.78523489932886e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7408, 'grad_norm': 0.47903576493263245, 'learning_rate': 7.718120805369128e-05, 'epoch': 0.08}\n",
      "{'loss': 0.656, 'grad_norm': 0.443562775850296, 'learning_rate': 7.651006711409397e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7989, 'grad_norm': 0.5590532422065735, 'learning_rate': 7.583892617449665e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7715, 'grad_norm': 0.6173529624938965, 'learning_rate': 7.516778523489934e-05, 'epoch': 0.08}\n",
      "{'loss': 0.847, 'grad_norm': 0.47957944869995117, 'learning_rate': 7.449664429530202e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8041, 'grad_norm': 0.6440302729606628, 'learning_rate': 7.382550335570471e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6988, 'grad_norm': 0.624933660030365, 'learning_rate': 7.315436241610739e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7213, 'grad_norm': 0.40409764647483826, 'learning_rate': 7.248322147651007e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8809, 'grad_norm': 0.43049129843711853, 'learning_rate': 7.181208053691275e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6118, 'grad_norm': 0.26980552077293396, 'learning_rate': 7.114093959731544e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7171, 'grad_norm': 0.3131740093231201, 'learning_rate': 7.046979865771812e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6916, 'grad_norm': 0.49136286973953247, 'learning_rate': 6.979865771812081e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7634, 'grad_norm': 0.45319807529449463, 'learning_rate': 6.912751677852349e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7549, 'grad_norm': 0.4520694613456726, 'learning_rate': 6.845637583892618e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8926, 'grad_norm': 0.49032723903656006, 'learning_rate': 6.778523489932886e-05, 'epoch': 0.08}\n",
      "{'loss': 0.795, 'grad_norm': 0.4750674068927765, 'learning_rate': 6.711409395973155e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8374, 'grad_norm': 0.6110014319419861, 'learning_rate': 6.644295302013423e-05, 'epoch': 0.08}\n",
      "{'loss': 0.602, 'grad_norm': 0.34794938564300537, 'learning_rate': 6.577181208053692e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8544, 'grad_norm': 0.6274498105049133, 'learning_rate': 6.51006711409396e-05, 'epoch': 0.08}\n",
      "{'loss': 0.8127, 'grad_norm': 0.5257865786552429, 'learning_rate': 6.442953020134228e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8074, 'grad_norm': 0.5915578007698059, 'learning_rate': 6.375838926174497e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6859, 'grad_norm': 0.7150654196739197, 'learning_rate': 6.308724832214765e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7444, 'grad_norm': 0.36271125078201294, 'learning_rate': 6.241610738255034e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8427, 'grad_norm': 0.6077240109443665, 'learning_rate': 6.174496644295302e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8614, 'grad_norm': 0.36844953894615173, 'learning_rate': 6.107382550335571e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7744, 'grad_norm': 0.6399166584014893, 'learning_rate': 6.04026845637584e-05, 'epoch': 0.09}\n",
      "{'loss': 0.9058, 'grad_norm': 0.6009271740913391, 'learning_rate': 5.973154362416108e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8579, 'grad_norm': 0.49451327323913574, 'learning_rate': 5.906040268456377e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7033, 'grad_norm': 0.49711498618125916, 'learning_rate': 5.838926174496645e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8379, 'grad_norm': 0.5141350030899048, 'learning_rate': 5.771812080536914e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7709, 'grad_norm': 0.4779299795627594, 'learning_rate': 5.704697986577181e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7561, 'grad_norm': 0.4379866123199463, 'learning_rate': 5.6375838926174495e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7028, 'grad_norm': 0.47594451904296875, 'learning_rate': 5.570469798657718e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7984, 'grad_norm': 0.577813982963562, 'learning_rate': 5.5033557046979866e-05, 'epoch': 0.09}\n",
      "{'loss': 0.746, 'grad_norm': 0.555027961730957, 'learning_rate': 5.436241610738255e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7961, 'grad_norm': 0.4973219335079193, 'learning_rate': 5.3691275167785237e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7952, 'grad_norm': 0.47456660866737366, 'learning_rate': 5.302013422818792e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7867, 'grad_norm': 0.4424826204776764, 'learning_rate': 5.234899328859061e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7668, 'grad_norm': 0.4194725751876831, 'learning_rate': 5.167785234899329e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8264, 'grad_norm': 0.5758056044578552, 'learning_rate': 5.100671140939598e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8262, 'grad_norm': 0.43810153007507324, 'learning_rate': 5.033557046979866e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7387, 'grad_norm': 0.37655410170555115, 'learning_rate': 4.966442953020135e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8241, 'grad_norm': 0.5645653605461121, 'learning_rate': 4.8993288590604034e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7638, 'grad_norm': 0.4917243719100952, 'learning_rate': 4.832214765100672e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7403, 'grad_norm': 0.5104051828384399, 'learning_rate': 4.76510067114094e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7958, 'grad_norm': 0.4889732003211975, 'learning_rate': 4.697986577181208e-05, 'epoch': 0.1}\n",
      "{'loss': 0.9542, 'grad_norm': 0.5642016530036926, 'learning_rate': 4.630872483221477e-05, 'epoch': 0.1}\n",
      "{'loss': 0.644, 'grad_norm': 0.48883822560310364, 'learning_rate': 4.5637583892617453e-05, 'epoch': 0.1}\n",
      "{'loss': 0.652, 'grad_norm': 0.5521753430366516, 'learning_rate': 4.496644295302014e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7258, 'grad_norm': 0.5818265080451965, 'learning_rate': 4.4295302013422824e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6995, 'grad_norm': 0.35299497842788696, 'learning_rate': 4.36241610738255e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7075, 'grad_norm': 0.4256817102432251, 'learning_rate': 4.295302013422819e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7756, 'grad_norm': 0.4875527322292328, 'learning_rate': 4.228187919463087e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7678, 'grad_norm': 0.5234969258308411, 'learning_rate': 4.161073825503356e-05, 'epoch': 0.1}\n",
      "{'loss': 0.8147, 'grad_norm': 0.5023317933082581, 'learning_rate': 4.0939597315436244e-05, 'epoch': 0.1}\n",
      "{'loss': 0.9447, 'grad_norm': 0.6488334536552429, 'learning_rate': 4.026845637583892e-05, 'epoch': 0.1}\n",
      "{'loss': 0.744, 'grad_norm': 1.1132405996322632, 'learning_rate': 3.959731543624161e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7099, 'grad_norm': 0.523278534412384, 'learning_rate': 3.89261744966443e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6471, 'grad_norm': 0.3484154939651489, 'learning_rate': 3.8255033557046985e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7105, 'grad_norm': 0.4510910212993622, 'learning_rate': 3.758389261744967e-05, 'epoch': 0.1}\n",
      "{'loss': 0.9074, 'grad_norm': 0.5549622774124146, 'learning_rate': 3.6912751677852356e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6877, 'grad_norm': 0.4394640624523163, 'learning_rate': 3.6241610738255034e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7768, 'grad_norm': 0.5456595420837402, 'learning_rate': 3.557046979865772e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7261, 'grad_norm': 0.672512412071228, 'learning_rate': 3.4899328859060405e-05, 'epoch': 0.1}\n",
      "{'loss': 0.733, 'grad_norm': 0.508339524269104, 'learning_rate': 3.422818791946309e-05, 'epoch': 0.1}\n",
      "{'loss': 0.808, 'grad_norm': 0.5565142035484314, 'learning_rate': 3.3557046979865775e-05, 'epoch': 0.1}\n",
      "{'loss': 0.8581, 'grad_norm': 0.5420466065406799, 'learning_rate': 3.288590604026846e-05, 'epoch': 0.1}\n",
      "{'loss': 0.8614, 'grad_norm': 0.41659557819366455, 'learning_rate': 3.221476510067114e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7509, 'grad_norm': 0.6976161003112793, 'learning_rate': 3.1543624161073825e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6303, 'grad_norm': 0.5201520323753357, 'learning_rate': 3.087248322147651e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8341, 'grad_norm': 0.45808449387550354, 'learning_rate': 3.02013422818792e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7612, 'grad_norm': 0.4403396546840668, 'learning_rate': 2.9530201342281884e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6455, 'grad_norm': 0.4023149311542511, 'learning_rate': 2.885906040268457e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7586, 'grad_norm': 0.4662207365036011, 'learning_rate': 2.8187919463087248e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6335, 'grad_norm': 0.6143750548362732, 'learning_rate': 2.7516778523489933e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7006, 'grad_norm': 0.4105823338031769, 'learning_rate': 2.6845637583892618e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8528, 'grad_norm': 0.6041774153709412, 'learning_rate': 2.6174496644295304e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7019, 'grad_norm': 0.7024753093719482, 'learning_rate': 2.550335570469799e-05, 'epoch': 0.11}\n",
      "{'loss': 0.731, 'grad_norm': 0.4987207055091858, 'learning_rate': 2.4832214765100674e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8068, 'grad_norm': 0.7057812213897705, 'learning_rate': 2.416107382550336e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7188, 'grad_norm': 0.5522210597991943, 'learning_rate': 2.348993288590604e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7262, 'grad_norm': 0.5390797257423401, 'learning_rate': 2.2818791946308727e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8744, 'grad_norm': 0.4516235888004303, 'learning_rate': 2.2147651006711412e-05, 'epoch': 0.11}\n",
      "{'loss': 0.841, 'grad_norm': 0.5228317975997925, 'learning_rate': 2.1476510067114094e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8342, 'grad_norm': 0.38592541217803955, 'learning_rate': 2.080536912751678e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8603, 'grad_norm': 0.5632182955741882, 'learning_rate': 2.013422818791946e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6665, 'grad_norm': 0.5527137517929077, 'learning_rate': 1.946308724832215e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7981, 'grad_norm': 0.4975312054157257, 'learning_rate': 1.8791946308724835e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8066, 'grad_norm': 0.4602273404598236, 'learning_rate': 1.8120805369127517e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8668, 'grad_norm': 0.38494643568992615, 'learning_rate': 1.7449664429530202e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7723, 'grad_norm': 0.46803128719329834, 'learning_rate': 1.6778523489932888e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7165, 'grad_norm': 0.5342234969139099, 'learning_rate': 1.610738255033557e-05, 'epoch': 0.12}\n",
      "{'loss': 0.6956, 'grad_norm': 0.41020041704177856, 'learning_rate': 1.5436241610738255e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8755, 'grad_norm': 0.6205398440361023, 'learning_rate': 1.4765100671140942e-05, 'epoch': 0.12}\n",
      "{'loss': 0.7013, 'grad_norm': 0.6703487038612366, 'learning_rate': 1.4093959731543624e-05, 'epoch': 0.12}\n",
      "{'loss': 0.9644, 'grad_norm': 0.6583790183067322, 'learning_rate': 1.3422818791946309e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8711, 'grad_norm': 0.6368722319602966, 'learning_rate': 1.2751677852348994e-05, 'epoch': 0.12}\n",
      "{'loss': 0.7045, 'grad_norm': 0.5334177017211914, 'learning_rate': 1.208053691275168e-05, 'epoch': 0.12}\n",
      "{'loss': 0.7768, 'grad_norm': 0.5232818722724915, 'learning_rate': 1.1409395973154363e-05, 'epoch': 0.12}\n",
      "{'loss': 0.7317, 'grad_norm': 0.48961713910102844, 'learning_rate': 1.0738255033557047e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8626, 'grad_norm': 0.5851580500602722, 'learning_rate': 1.006711409395973e-05, 'epoch': 0.12}\n",
      "{'loss': 0.6889, 'grad_norm': 0.3651703894138336, 'learning_rate': 9.395973154362418e-06, 'epoch': 0.12}\n",
      "{'loss': 0.7146, 'grad_norm': 0.5263110995292664, 'learning_rate': 8.724832214765101e-06, 'epoch': 0.12}\n",
      "{'loss': 0.681, 'grad_norm': 0.48431089520454407, 'learning_rate': 8.053691275167785e-06, 'epoch': 0.12}\n",
      "{'loss': 0.798, 'grad_norm': 0.591219961643219, 'learning_rate': 7.382550335570471e-06, 'epoch': 0.12}\n",
      "{'loss': 0.7346, 'grad_norm': 0.5172736644744873, 'learning_rate': 6.7114093959731546e-06, 'epoch': 0.12}\n",
      "{'loss': 0.6807, 'grad_norm': 0.5229959487915039, 'learning_rate': 6.04026845637584e-06, 'epoch': 0.12}\n",
      "{'loss': 0.7111, 'grad_norm': 0.46068117022514343, 'learning_rate': 5.3691275167785235e-06, 'epoch': 0.12}\n",
      "{'loss': 0.6741, 'grad_norm': 0.46232596039772034, 'learning_rate': 4.697986577181209e-06, 'epoch': 0.12}\n",
      "{'loss': 0.7368, 'grad_norm': 0.419106125831604, 'learning_rate': 4.026845637583892e-06, 'epoch': 0.12}\n",
      "{'loss': 0.8114, 'grad_norm': 0.4512456953525543, 'learning_rate': 3.3557046979865773e-06, 'epoch': 0.12}\n",
      "{'loss': 0.8199, 'grad_norm': 0.5609250068664551, 'learning_rate': 2.6845637583892617e-06, 'epoch': 0.12}\n",
      "{'loss': 0.9537, 'grad_norm': 0.6566202044487, 'learning_rate': 2.013422818791946e-06, 'epoch': 0.12}\n",
      "{'loss': 0.6997, 'grad_norm': 0.44357046484947205, 'learning_rate': 1.3422818791946309e-06, 'epoch': 0.12}\n",
      "{'loss': 0.836, 'grad_norm': 0.5289145112037659, 'learning_rate': 6.711409395973154e-07, 'epoch': 0.12}\n",
      "{'loss': 0.614, 'grad_norm': 0.46565479040145874, 'learning_rate': 0.0, 'epoch': 0.12}\n",
      "{'train_runtime': 2961.0576, 'train_samples_per_second': 2.026, 'train_steps_per_second': 0.507, 'train_loss': 0.8732972733179728, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.8732972733179728, metrics={'train_runtime': 2961.0576, 'train_samples_per_second': 2.026, 'train_steps_per_second': 0.507, 'total_flos': 1.07495527809024e+17, 'train_loss': 0.8732972733179728, 'epoch': 0.125})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  \n",
    "    train_dataset=train_data,  \n",
    "    eval_dataset=test_data,  \n",
    "    dataset_text_field=\"prompt\",  \n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,  \n",
    "        gradient_accumulation_steps=4,  \n",
    "        num_train_epochs=50, \n",
    "        warmup_steps=10,  \n",
    "        max_steps=1500,  \n",
    "        learning_rate=2e-4,  \n",
    "        logging_steps=5,  \n",
    "        output_dir=\"outputs_llama3.2_1b_sft\", \n",
    "        optim=\"adamw_hf\",  \n",
    "        save_strategy=\"epoch\",  \n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),  # Collator for causal language modeling\n",
    ")\n",
    "\n",
    "# Run training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d0463-9375-400a-8f2c-9b9b73d1a2ca",
   "metadata": {},
   "source": [
    "### **Merge and Save the Finetuned Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f59d5ec6-5219-4936-8e65-e5d29f60d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b39a0a17043499c866e28e2dcad3bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = \"llama-3.2-3b-finetune-xlam-function-calling-60k\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "merged_model= PeftModel.from_pretrained(base_model, new_model)\n",
    "merged_model= merged_model.merge_and_unload()\n",
    "\n",
    "merged_model.save_pretrained(\"merged_model_sft3.2_3b\",safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_model_sft3.2_3b\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8548d-fe06-45d5-bed2-28979667b35f",
   "metadata": {},
   "source": [
    "### **Loading the Saved Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8f59ef-b424-4527-9cfe-96636aee40bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff7b29aa514875975eb7c860312479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\"merged_model_sft3.2_3b\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(\"merged_model_sft3.2_3b\")\n",
    "finetuned_tokenizer.pad_token = finetuned_tokenizer.eos_token\n",
    "finetuned_tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109e4b9-74a2-44d2-be0e-615299e59f67",
   "metadata": {},
   "source": [
    "### **Push the model to Huggingface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e775-66c7-4fe2-b3a7-fc7bb4e10cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geek/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/modeling_utils.py:2670: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87233f43c14c49b38bd2c72d872122bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09dcbd4a3b3046d0be9b111ffd43027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871e6c12ca214d9697f4480eac7de572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/abdulmannan-01/Llama-3.2-3b-finetuned-for-json-generation/commit/d05c6dbd9445283bbb3be184393f94b5dc3f6ccc', commit_message='Upload tokenizer', commit_description='', oid='d05c6dbd9445283bbb3be184393f94b5dc3f6ccc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_name = \"Amin-01/Llama-3.2-3b-finetuned-for-json-generation\"\n",
    "\n",
    "finetuned_model.push_to_hub(repo_name)\n",
    "finetuned_tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c46105-5a30-421b-8362-c17b6ac0411a",
   "metadata": {},
   "source": [
    "# **Inference Using Finetuned Huggingface Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2592fd9-338c-4d0a-bb34-49587ef6fdce",
   "metadata": {},
   "source": [
    "### **Load Model From HuggingFace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb7f0b-14e4-4390-9193-0068f1065b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Amin-01/Llama-3.2-3b-finetuned-for-json-generation\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(\"Amin-01/Llama-3.2-3b-finetuned-for-json-generation\")\n",
    "finetuned_tokenizer.pad_token = finetuned_tokenizer.eos_token\n",
    "finetuned_tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d12d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens if not already present\n",
    "special_tokens = {\n",
    "    'additional_special_tokens': [\n",
    "        '<|begin_of_text|>',\n",
    "        '<|start_header_id|>',\n",
    "        '<|end_header_id|>',\n",
    "        '<|eot_id|>',\n",
    "        '<|endoftext|>'\n",
    "    ]\n",
    "}\n",
    "num_added_toks = finetuned_tokenizer.add_special_tokens(special_tokens)\n",
    "if num_added_toks > 0:\n",
    "    finetuned_model.resize_token_embeddings(len(finetuned_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f78606b-e95a-4259-bc98-cbc320e4832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(query):\n",
    "    # Construct the prompt according to the Llama3.2-1B chat template\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\"\n",
    "        + query\n",
    "        + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    )\n",
    "    # Tokenize the prompt\n",
    "    inputs = finetuned_tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8910e51-01a1-4e14-b2a3-c9fbba24788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assistant_response(output_text):\n",
    "    assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    start_idx = output_text.find(assistant_header)\n",
    "    if start_idx == -1:\n",
    "        print(\"Assistant header not found in the output.\")\n",
    "        return ''\n",
    "    start_idx += len(assistant_header)\n",
    "    \n",
    "    # Extract the assistant's content\n",
    "    assistant_content = output_text[start_idx:].strip()\n",
    "    \n",
    "    # Stop at the next occurrence of the assistant header to avoid repeated outputs\n",
    "    split_token = '<|start_header_id|>assistant<|end_header_id|>'\n",
    "    end_idx = assistant_content.find(split_token)\n",
    "    if end_idx != -1:\n",
    "        assistant_content = assistant_content[:end_idx].strip()\n",
    "    \n",
    "    # Remove any trailing special tokens\n",
    "    special_tokens = [\n",
    "        '<|eot_id|>',\n",
    "        '<|endoftext|>',\n",
    "        '<|end_of_text|>',\n",
    "        '<|end_header_id|>',\n",
    "        '<|start_header_id|>',\n",
    "        '<|begin_of_text|>'\n",
    "    ]\n",
    "    \n",
    "    # Remove special tokens from the end of assistant_content\n",
    "    while True:\n",
    "        for token in special_tokens:\n",
    "            if assistant_content.endswith(token):\n",
    "                assistant_content = assistant_content[:-len(token)].strip()\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return assistant_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "356862ae-02c3-4e30-a837-ba0e4213316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, inputs):\n",
    "    eot_token_id = finetuned_tokenizer.convert_tokens_to_ids('<|eot_id|>')\n",
    "    \n",
    "    # Generate the output\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        pad_token_id=finetuned_tokenizer.eos_token_id,\n",
    "        eos_token_id=eot_token_id, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    output_text = finetuned_tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    # Uncomment the line below to see the full generated text including special tokens\n",
    "    #print('Model Output:', output_text)\n",
    "    assistant_response = extract_assistant_response(output_text)\n",
    "    return assistant_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b54bf76a-6a84-40fb-8132-d4dd803d0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isJsonString(input_string):\n",
    "    try:\n",
    "        json.loads(input_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4947beb0-a6c0-4796-a68d-4e2292595970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"auto_complete\", \"arguments\": {\"query\": \"winter coat\", \"store\": \"Kohls\"}}, {\"name\": \"auto_complete\", \"arguments\": {\"query\": \"kitchen appliance\", \"store\": \"Wayfair\"}}]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Fetch auto-complete results for 'winter coat' from Kohls and 'kitchen appliance' from Wayfair.\"\n",
    "inputs1 = prepare_input(query1)\n",
    "response1 = generate_response(finetuned_model, inputs1)\n",
    "\n",
    "print(\"Generated JSON response:\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33cd9fa2-b676-4a7c-a6dd-256ed5f0d8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc323780-68ab-48f1-b3b8-46392656f5d8",
   "metadata": {},
   "source": [
    "### **Testing on Different Text Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0878b9c9-85f5-400b-aa41-d3dc3a8e5ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"binance_ticker\", \"arguments\": {\"symbol\": \"ETH/BTC\", \"interval\": \"1h\", \"time_period\": 14}}]\n"
     ]
    }
   ],
   "source": [
    "query2 = \"'ETH/BTC' using a 1h interval and a time period of 14?\"\n",
    "inputs2 = prepare_input(query2)\n",
    "response2 = generate_response(finetuned_model, inputs2)\n",
    "\n",
    "print(\"Generated JSON response:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "493971b4-c855-447b-84e6-2adff96d2a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb968a18-1fe2-49ce-8b10-6432c7cca629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_specific_chain\", \"arguments\": {\"chain\": \"ethereum\"}}]\n"
     ]
    }
   ],
   "source": [
    "query3 = \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for 'ethereum'?\"\n",
    "inputs3 = prepare_input(query3)\n",
    "response3 = generate_response(finetuned_model, inputs3)\n",
    "\n",
    "print(\"Generated JSON response:\", response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "587707a5-0f7c-4ccb-ac54-f49f08379877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30e1fa37-4e91-490b-9ea4-041a2daf9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"generate_password\", \"arguments\": {\"length\": 12}}]\n"
     ]
    }
   ],
   "source": [
    "query4 = \"I need a new password. Can you generate one for me?\"\n",
    "inputs4 = prepare_input(query4)\n",
    "response4 = generate_response(finetuned_model, inputs4)\n",
    "\n",
    "print(\"Generated JSON response:\", response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ed2f6b3-d3ab-4f45-a506-db4e2d032bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5062be-5548-4efb-abce-122159fe8b2a",
   "metadata": {},
   "source": [
    "### **Testing the Valid JSON Generation by providing non-valid JSONs and lengthy text queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ca63cd9-6587-4682-9340-bae5415ad05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"getuserbyname\", \"arguments\": {\"username\": \"JohnDoe\"}}]\n"
     ]
    }
   ],
   "source": [
    "query5 = '{\"id\": 1, \"name\": \"John Doe\", \"age\": 29, \"is_student\": false,}'\n",
    "inputs5 = prepare_input(query5)\n",
    "response5 = generate_response(finetuned_model, inputs5)\n",
    "\n",
    "print(\"Generated JSON response:\", response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db80b023-9667-4231-8f7a-0f7c1ad0113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "268d0f70-fdcd-485b-85d7-f705af50b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"parse_fruit\", \"arguments\": {\"fruits\": \"apple,banana,orange\", \"quantity\": 3}}]\n"
     ]
    }
   ],
   "source": [
    "query6 = '{\"fruits\": [\"apple\", \"banana\", \"orange\", \"quantity\": 3}'\n",
    "inputs6 = prepare_input(query6)\n",
    "response6 = generate_response(finetuned_model, inputs6)\n",
    "\n",
    "print(\"Generated JSON response:\", response6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e05f465d-6006-43d3-ae87-49965fb42ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e1040fc-7ffa-47a8-9842-d643a5ff667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_employee_details\", \"arguments\": {\"employee\": \"name: Jane Smith, designation: Software Engineer\"}}]\n"
     ]
    }
   ],
   "source": [
    "query7 = '{\"employee\": \"name\": \"Jane Smith\", \"designation\": \"Software Engineer\"}'\n",
    "inputs7 = prepare_input(query7)\n",
    "response7 = generate_response(finetuned_model, inputs7)\n",
    "\n",
    "print(\"Generated JSON response:\", response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a732521f-2a73-412f-95a1-d151db7f2a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efc967f6-aa61-48d2-a1c1-5856015e5d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"getdata\", \"arguments\": {\"status\": \"success\"}}]\n"
     ]
    }
   ],
   "source": [
    "query8 = '{\"status\": \"success\" \"data\": null}'\n",
    "inputs8 = prepare_input(query8)\n",
    "response8 = generate_response(finetuned_model, inputs8)\n",
    "\n",
    "print(\"Generated JSON response:\", response8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01a65bdd-0fac-4ff4-b903-8644f53f74ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec02f890-a67f-49e8-bd6b-3e060c2988af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_products\", \"arguments\": {\"products\": [{\"id\": 1, \"name\": \"Laptop\", \"price\": 999.99}, {\"id\": 2, \"name\": \"Mouse\", \"price\": 19.99}]}}]\n"
     ]
    }
   ],
   "source": [
    "query9 = '{\"products\": [{\"id\": 1, \"name\": \"Laptop\", \"price\": 999.99} {\"id\": 2, \"name\": \"Mouse\", \"price\": 19.99}]}'\n",
    "inputs9 = prepare_input(query9)\n",
    "response9 = generate_response(finetuned_model, inputs9)\n",
    "\n",
    "print(\"Generated JSON response:\", response9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1fa6d69-56bc-4fe0-8b10-1201ef2bb045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20373053-b1bd-4b92-b707-b2fa201f7948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"getprofile\", \"arguments\": {\"name\": \"John Doe\", \"age\": 34, \"occupation\": \"Software Engineer\", \"city\": \"San Francisco\", \"company\": \"Tech Innovators\", \"university\": \"Stanford University\", \"years_of_experience\": 10, \"area_of_expertise\": \"Artificial Intelligence\"}}]\n"
     ]
    }
   ],
   "source": [
    "query10 = 'John Doe is a 34-year-old software engineer living in San Francisco. He works for a tech startup called Tech Innovators, where he leads the AI research team. John graduated from Stanford University with a degree in Computer Science and has over 10 years of experience in the field of artificial intelligence. '\n",
    "inputs10 = prepare_input(query10)\n",
    "response10 = generate_response(finetuned_model, inputs10)\n",
    "\n",
    "print(\"Generated JSON response:\", response10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6bf2225-a630-4b0c-8315-3259384072df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1757349e-79fa-4b4b-8779-86a0dbcc1b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_project_info\", \"arguments\": {\"project_name\": \"Building an AI system for predictive analytics in business operations\"}}, {\"name\": \"get_project_info\", \"arguments\": {\"project_name\": \"Building an AI system for predictive analytics in business operations\"}}, {\"name\": \"get_project_info\", \"arguments\": {\"project_name\": \"Building an AI system for predictive analytics in business operations\"}}, {\"name\": \"get_project_info\", \"arguments\": {\"project_name\": \"Building an AI system for predictive analytics in business operations\"}}]\n"
     ]
    }
   ],
   "source": [
    "query11 = \"John's current project involves building an AI system that helps businesses optimize their operations using predictive analytics. He is passionate about leveraging machine learning to solve complex business problems. Outside of work, John enjoys hiking, photography, and volunteering at local community events. He is also a mentor for aspiring software developers and often participates in hackathons as a judge.\"\n",
    "inputs11 = prepare_input(query11)\n",
    "response11 = generate_response(finetuned_model, inputs11)\n",
    "\n",
    "print(\"Generated JSON response:\", response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cfd5f07-40ad-4dbe-968e-35097c2f73f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15926e98-95b1-4cd0-b98f-9f9a90799e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"family_profile\", \"arguments\": {\"first_name\": \"John\", \"last_name\": \"Doe\", \" occupation\": \"Graphic Designer\", \"children\": [\"Emily\", \"Michael\"], \"family_interests\": [\"weekend trips\", \"national parks\", \"beach\"]}}]\n"
     ]
    }
   ],
   "source": [
    "query12 = \"John is married to Jane Doe, who works as a graphic designer. They have two children: Emily, aged 5, and Michael, aged 3. As a family, they enjoy weekend trips to national parks and spending time at the beach.\"\n",
    "inputs12 = prepare_input(query12)\n",
    "response12 = generate_response(finetuned_model, inputs12)\n",
    "\n",
    "print(\"Generated JSON response:\", response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20f72989-6f2c-4170-941a-6c5ee4acba51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "415263b5-ce2a-4186-85cb-22cee493485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_the_expertise\", \"arguments\": {\"name\": \"John\", \"language\": \"Python\", \"framework\": \"TensorFlow\", \"cloud\": \"AWS\", \"topic\": \"AI\", \"experience\": \"keynote speaker\"}}]\n"
     ]
    }
   ],
   "source": [
    "query13 = \"John's professional expertise includes programming languages such as Python, Java, and C++. He is proficient in frameworks like TensorFlow and PyTorch, and he is familiar with cloud services such as AWS and GCP. He regularly publishes articles on AI and machine learning topics and has been a keynote speaker at various tech conferences.\"\n",
    "inputs13 = prepare_input(query13)\n",
    "response13 = generate_response(finetuned_model, inputs13)\n",
    "\n",
    "print(\"Generated JSON response:\", response13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba177f7b-a538-43a6-8ca0-0f6812bf4604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "903a02fe-b3a5-40e3-a7f2-9fcb06318ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"analyze_personality\", \"arguments\": {\"name\": \"Natalie\"}}, {\"name\": \"analyze_personality\", \"arguments\": {\"name\": \"Dan\"}}, {\"name\": \"analyze_personality\", \"arguments\": {\"name\": \"Sean\"}}, {\"name\": \"analyze_personality\", \"arguments\": {\"name\": \"Alice\"}}, {\"name\": \"analyze_personality\", \"arguments\": {\"name\": \"Sara\"}}]\n"
     ]
    }
   ],
   "source": [
    "query14 = \"Dan, Natalie and Sean went running together. The three of them are runners. Natalie is 45 years old while Both Dan and Sean are approaching 47. Natalie is working as an engineer in a tech company with Dan, they met there. Sean has a daughter who likes swimming, so he also goes swimming with her. Her name is Alice. Alice likes eating a pizza. Her best friend, Sara, is about the same age and enjoys icecream the most.\"\n",
    "inputs14 = prepare_input(query14)\n",
    "response14 = generate_response(finetuned_model, inputs14)\n",
    "\n",
    "print(\"Generated JSON response:\", response14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a33a853-158c-4868-932b-477467c75663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f459d28-43eb-49ec-b3cb-54444dfa6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_all_characters\", \"arguments\": {\"text\": \"Once upon a time in a small village, there were ten unique individuals. There was Amelia, the talented artist, always seen with a sketchpad in her hand. Next was Benjamin, the curious scientist, constantly conducting experiments in his backyard. Clara, the kind-hearted nurse, spent her days tending to the ill and the injured. Darren, the mischievous trickster, always had a prank up his sleeve. Eliza, the aspiring chef, could be found in her kitchen, concocting delicious recipes. Fred, the wise old man, spent his time under his favorite tree, sharing stories with anyone who would listen. Grace, the passionate teacher, inspired her students with her energetic lessons. Harry, the adventurous explorer, was always venturing into the unknown, seeking new discoveries. Isabella, the gentle gardener, nurtured her magnificent botanical creations. Lastly, Jackson, the compassionate volunteer, dedicated his time to helping those less fortunate. These ten individuals, though different in their pursuits, shared a common love for their village and one another. Their unique talents and selflessness came together, creating a harmonious community that thrived, celebrated, and most importantly, lived happily ever after.\"}}]\n"
     ]
    }
   ],
   "source": [
    "query15 = \"Once upon a time in a small village, there were ten unique individuals. There was Amelia, the talented artist, always seen with a sketchpad in her hand. Next was Benjamin, the curious scientist, constantly conducting experiments in his backyard. Clara, the kind-hearted nurse, spent her days tending to the ill and the injured. Darren, the mischievous trickster, always had a prank up his sleeve. Eliza, the aspiring chef, could be found in her kitchen, concocting delicious recipes. Fred, the wise old man, spent his time under his favorite tree, sharing stories with anyone who would listen. Grace, the passionate teacher, inspired her students with her energetic lessons. Harry, the adventurous explorer, was always venturing into the unknown, seeking new discoveries. Isabella, the gentle gardener, nurtured her magnificent botanical creations. Lastly, Jackson, the compassionate volunteer, dedicated his time to helping those less fortunate. These ten individuals, though different in their pursuits, shared a common love for their village and one another. Their unique talents and selflessness came together, creating a harmonious community that thrived, celebrated, and most importantly, lived happily ever after.\"\n",
    "inputs15 = prepare_input(query15)\n",
    "response15 = generate_response(finetuned_model, inputs15)\n",
    "\n",
    "print(\"Generated JSON response:\", response15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e612b770-baf9-4874-b56c-c51f41e05846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dad1480-78f8-426a-9590-4b615307794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_contact_info\", \"arguments\": {\"phone\": \"123-456-7890\", \"email\": \"example@example.com\"}}, {\"name\": \"get_preferences\", \"arguments\": {\"contact_time\": \"morning\", \"newsletter_subscribed\": true}}]\n"
     ]
    }
   ],
   "source": [
    "query16 = '{\"contact\": {\"phone\": 123-456-7890, \"email\": \"example@example.com\"}, \"preferences\": {\"contact_time\": \"morning\", \"newsletter_subscribed\": true}}'\n",
    "inputs16 = prepare_input(query16)\n",
    "response16 = generate_response(finetuned_model, inputs16)\n",
    "\n",
    "print(\"Generated JSON response:\", response16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66671aab-203e-4719-8613-7e2b90d03a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "195b7458-33ee-4946-8e85-59c9cde6c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"get_all_books\", \"arguments\": {\"books\": [{\"title\": \"The Catcher in the Rye\", \"author\": \"J.D. Salinger\"}, {\"title\": \"To Kill a Mockingbird\", \"author\": \"Harper Lee\"}]}}]\n"
     ]
    }
   ],
   "source": [
    "query17 = '{\"books\": [{\"title\": \"The Catcher in the Rye\", \"author\": \"J.D. Salinger\"}, {\"title\": \"To Kill a Mockingbird\", \"author\": \"Harper Lee\"}'\n",
    "inputs17 = prepare_input(query17)\n",
    "response17 = generate_response(finetuned_model, inputs17)\n",
    "\n",
    "print(\"Generated JSON response:\", response17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a47bcaa-6d72-4921-b053-34bf319da0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ce97215-3279-4dc0-8a5c-a3fa98199975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"sports_league\", \"arguments\": {\"sports_league\": \"National Basketball League\", \"teams\": [{\"name\": \"Lakers\", \"city\": \"Los Angeles\", \"players\": [{\"name\": \"LeBron James\", \"position\": \"SF\"}, {\"name\": \"Anthony Davis\", \"position\": \"PF\"}]}, {\"name\": \"Warriors\", \"city\": \"San Francisco\", \"players\": [{\"name\": \"Stephen Curry\", \"position\": \"PG\"}, {\"name\": \"Klay Thompson\", \"position\": \"SG\"}]}], \"sponsors\": [{\"company\": \"Nike\", \"amount\": 2000000}, {\"company\": \"Adidas\", \"amount\": 1500000}]}}]\n"
     ]
    }
   ],
   "source": [
    "query18 = '{\"sports_league\": {\"name\": \"National Basketball League\", \"teams\": [{\"name\": \"Lakers\", \"city\": \"Los Angeles\", \"players\": [{\"name\": \"LeBron James\", \"position\": \"SF\"}, {\"name\": \"Anthony Davis\", \"position\": \"PF\"}]}, {\"name\": \"Warriors\", \"city\": \"San Francisco\", \"players\": [{\"name\": \"Stephen Curry\", \"position\": \"PG\"}, {\"name\": \"Klay Thompson\", \"position\": \"SG\"}]}], \"sponsors\": [{\"company\": \"Nike\", \"amount\": 2000000}, {\"company\": \"Adidas\", \"amount\": 1500000}]}}'\n",
    "inputs18 = prepare_input(query18)\n",
    "response18 = generate_response(finetuned_model, inputs18)\n",
    "\n",
    "print(\"Generated JSON response:\", response18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e7b28071-c16d-48c2-b646-988a5e7f6c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b884a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"getresearchlab\", \"arguments\": {\"name\": \"AI Institute\", \"location\": {\"city\": \"Cambridge\", \"state\": \"MA\"}, \"projects\": [{\"name\": \"AI for Healthcare\"}, {\"name\": \"Autonomous Vehicles\"}]}}]\n"
     ]
    }
   ],
   "source": [
    "query19 = '{\"research_lab\": {\"name\": \"AI Institute\", \"location\": {\"city\": \"Cambridge\", \"state\": \"MA\"}, \"projects\": [{\"name\": \"AI for Healthcare\"}, {\"name\": \"Autonomous Vehicles\"]}}'\n",
    "inputs19 = prepare_input(query19)\n",
    "response19 = generate_response(finetuned_model, inputs19)\n",
    "\n",
    "print(\"Generated JSON response:\", response19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d4885cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb1b6a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: [{\"name\": \"tech_conference\", \"arguments\": {\"name\": \"Future of AI\", \"date\": \"2024-09-15\", \"location\": {\"city\": \"San Francisco\", \"state\": \"CA\"}, \"speakers\": [{\"name\": \"Andrew Ng\"}, {\"name\": \"Geoffrey Hinton\"}]}}]\n"
     ]
    }
   ],
   "source": [
    "query20 = '{\"tech_conference\": {\"name\": \"Future of AI\", \"date\": \"2024-09-15\", \"location\": {\"city\": \"San Francisco\", \"state\": \"CA\"}, \"speakers\": [{\"name\": \"Andrew Ng\"}, {\"name\": \"Geoffrey Hinton\"]}}}'\n",
    "inputs20 = prepare_input(query20)\n",
    "response20 = generate_response(finetuned_model, inputs20)\n",
    "\n",
    "print(\"Generated JSON response:\", response20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7130ba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isJsonString(response20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
