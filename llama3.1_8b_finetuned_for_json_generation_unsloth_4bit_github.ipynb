{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetuning Llama3.1-8B Model on Salesforce/Xlam-function-calling Dataset Using Unsloth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Apply Lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Formatting the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answers', 'query', 'tools', 'id'],\n",
      "    num_rows: 60000\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bed577d8dd42c0934d14603c102ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answers', 'query', 'tools', 'id', 'text'],\n",
      "    num_rows: 60000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instruction = \"You are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\"\n",
    "    inputs       = examples[\"query\"]\n",
    "    outputs      = examples[\"answers\"]\n",
    "    texts = []\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Salesforce/xlam-function-calling-60k\",split=\"train\")\n",
    "print(dataset)\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\\n\\n### Input:\\nI need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for \\'ethereum\\'?\\n\\n### Response:\\n[{\"name\": \"web_chain_details\", \"arguments\": {\"chain_slug\": \"ethereum\"}}]<|end_of_text|>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting Up Training Arguments and Training for SFTTrainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f39a8cc6c64f2aa3fba44f50447d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 500,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs_llama3.1_8b_unsloth_4bit\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 60,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 50:11, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.765600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.835400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.610500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.540700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.591900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.556300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.464400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.631800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.592200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.554300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.569400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.491300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.607600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.614800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.577300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.676900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.578600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.591500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.607600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.594200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.608500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.537700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.498600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.575300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.589300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.602800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.536600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.537700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.423200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.655200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.467700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.601200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.529200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.546900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.494100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.583300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.505700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.541700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.535700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.584600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.516100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.405600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.649600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.484700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.418100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.498600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.565500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.410200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.524500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.341700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.460100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.536600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.384800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.323100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.560700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.544100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.479300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.532200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.610300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.374100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.483500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.512400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.466800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.524700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.351100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.407400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.410300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.585300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.325800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>0.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>0.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.459700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>0.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>0.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>0.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>0.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.337000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>0.610300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>0.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>0.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>0.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>0.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>0.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>0.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>0.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>0.414300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>0.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>0.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>0.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>0.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>0.557700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>0.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>0.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>0.603100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>0.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>0.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>0.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>0.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>0.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.597200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>0.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>0.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>0.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>0.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>0.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>0.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>0.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>0.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>0.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>0.400500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>0.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>0.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>0.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>0.346400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>0.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.532400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\\n\\n### Input:\\nI need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for \\'ethereum\\'?\\n\\n### Response:\\n[{\"name\": \"get_blockchain_details\", \"arguments\": {\"name\": \"ethereum\"}}]<|end_of_text|>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"You are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\", # instruction\n",
    "        \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for \\'ethereum\\'?\", # input\n",
    "        \"\", # output \n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Continue the fibonnaci sequence.\n",
      "\n",
      "### Input:\n",
      "I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for 'ethereum'?\n",
      "\n",
      "### Response:\n",
      "[{\"name\": \"blockchain\", \"arguments\": {\"slug\": \"ethereum\"}}]<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Continue the fibonnaci sequence.\", # instruction\n",
    "        \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for \\'ethereum\\'?\", # input\n",
    "        \"\", # output \n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save the Finetuned Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora-model\") \n",
    "tokenizer.save_pretrained(\"llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora-model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# alpaca_prompt = You MUST copy from above!\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"You are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\", # instruction\n",
    "        \"I need an analysis report on the impact of our latest marketing campaign. Include data such as conversion rates, customer engagement metrics, social media performance, and any sales growth. Provide insights on which segments of the campaign were most successful and suggest areas for improvement.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Push the model to Huggingface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"Amin-01/Llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora\", token = \"hf_token\") \n",
    "tokenizer.push_to_hub(\"Amin-01/Llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora\", token = \"hf_token\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference Using Finetuned Huggingface Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Model From HuggingFace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525b7daf759f44adb2df5a69902d8b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4408ee1b2e9d4ea3927bdc136e12166b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea9d7a84c1440f885dacbe79daae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ac7915b916417695179b4d3830236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cb91d92f064bd992df5f94b936ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca866b6b19cd4778b0fa09144180a552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"Amin-01/Llama-3.1-8b-finetuned-for-json-generation-unsloth-4bit-lora\"\n",
    "\n",
    "# Load the model using Unsloth's FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Enable the model for inference\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the tokenizer has the required special tokens\n",
    "special_tokens = {\n",
    "    'additional_special_tokens': [\n",
    "        '<|begin_of_text|>',\n",
    "        '<|start_header_id|>',\n",
    "        '<|end_header_id|>',\n",
    "        '<|eot_id|>',\n",
    "        '<|endoftext|>'\n",
    "    ]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "if num_added_toks > 0:\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Alpaca prompt template\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare the input\n",
    "def prepare_input(query):\n",
    "    instruction = \"You are a helpful assistant. Your task is to convert any input into valid JSON. Only provide the JSON response, no extra information:\"\n",
    "    input_text = query\n",
    "    prompt = alpaca_prompt.format(\n",
    "        instruction,\n",
    "        input_text,\n",
    "        \"\"  # Output left blank for generation\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    return inputs\n",
    "\n",
    "# Function to extract the assistant's response\n",
    "def extract_response(output_text):\n",
    "    response_header = \"### Response:\"\n",
    "    start_idx = output_text.find(response_header)\n",
    "    if start_idx == -1:\n",
    "        print(\"Response header not found in the output.\")\n",
    "        return ''\n",
    "    start_idx += len(response_header)\n",
    "    assistant_content = output_text[start_idx:].strip()\n",
    "\n",
    "    # Remove any trailing special tokens\n",
    "    special_tokens = [\n",
    "        '<|end_of_text|>',\n",
    "        '<|endoftext|>',\n",
    "        '<|eot_id|>',\n",
    "        tokenizer.eos_token,\n",
    "    ]\n",
    "\n",
    "    for token in special_tokens:\n",
    "        assistant_content = assistant_content.replace(token, '').strip()\n",
    "\n",
    "    return assistant_content\n",
    "\n",
    "# Function to generate the response\n",
    "def generate_response(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    #print(\"Raw Model Response:\",output_text)\n",
    "    assistant_response = extract_response(output_text)\n",
    "    return assistant_response\n",
    "\n",
    "# Function to check if a string is valid JSON\n",
    "def isJsonString(input_string):\n",
    "    try:\n",
    "        json.loads(input_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Function to evaluate the model's performance\n",
    "def evaluate_model_performance(model, queries, max_retries=5):\n",
    "    total_queries = len(queries)\n",
    "    valid_json_count = 0\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        inputs = prepare_input(query)\n",
    "        response = None\n",
    "\n",
    "        # Retry mechanism for invalid JSONs\n",
    "        for attempt in range(max_retries):\n",
    "            response = generate_response(model, inputs)\n",
    "            if isJsonString(response):\n",
    "                break\n",
    "\n",
    "        is_valid = isJsonString(response)\n",
    "\n",
    "        print(f\"Query {i+1}: {query}\")\n",
    "        print(f\"Generated JSON response: {response}\")\n",
    "\n",
    "        if is_valid:\n",
    "            print(\"The response is valid JSON.\")\n",
    "            valid_json_count += 1\n",
    "        else:\n",
    "            print(\"The response is not valid JSON.\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Compute the percentage of valid JSON outputs\n",
    "    valid_percentage = (valid_json_count / total_queries) * 100\n",
    "    print(f\"Valid JSON responses: {valid_json_count}/{total_queries} ({valid_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    # 5 big textual prompts\n",
    "    \"I need an analysis report on the impact of our latest marketing campaign. Include data such as conversion rates, customer engagement metrics, social media performance, and any sales growth. Provide insights on which segments of the campaign were most successful and suggest areas for improvement.\",\n",
    "    \"Please generate a monthly sales report for our e-commerce platform, detailing total sales, top-performing products, customer demographics, and return rates. Include comparisons to the previous month and highlight any notable trends or anomalies.\",\n",
    "    \"Create a technical specification document for the new software system we're developing. Include sections on system architecture, database design, user interfaces, security protocols, scalability requirements, and integration with existing systems.\",\n",
    "    \"Can you provide a strategic plan for expanding our business into new international markets? The plan should cover potential target countries, market entry strategies, competitive analysis, legal considerations, and estimated costs. Highlight key opportunities and risks.\",\n",
    "    \"Generate a risk assessment report for our cloud infrastructure. The report should analyze potential security threats, vulnerabilities, compliance issues, and disaster recovery plans. Recommend best practices for improving system security and resilience.\",\n",
    "    # 25 big and complex invalid JSONs\n",
    "    \"{'payment': {'transactionID': 456789, 'amount': 100.00, 'currency': 'USD', 'method': 'Credit Card', 'status': 'Pending', 'details': {'cardNumber': '**** **** **** 1234', 'expiryDate': '12/23'}}}\",  # Valid JSON\n",
    "    \"{'portfolio': {'investor': 'Jane Doe', 'stocks': [{'ticker': 'AAPL', 'shares': 50, 'averagePrice': 150}, {'ticker': 'GOOG', 'shares': 30, 'averagePrice': 2500}], 'totalValue': 180000}\",  # Missing closing brace\n",
    "    \"{'jobApplication': {'candidateName': 'Alice Doe', 'position': 'Software Engineer', 'status': 'Under Review', 'interviews': [{'round': 1, 'interviewer': 'John Smith'}, {'round': 2, 'interviewer': 'Sara Lee'}], 'notes': 'Strong candidate, needs to improve coding skills'}}\",  # Valid JSON\n",
    "    \"{'orderID': 12345, 'customer': {'name': 'Alice Johnson', 'email': 'alice@example.com'}, 'items': [{'productID': 567, 'productName': 'Laptop', 'quantity': 1, 'price': 999.99}, {'productID': 789, 'productName': 'Mouse', 'quantity': 2, 'price': 19.99}], 'total': 1039.97\",  # Missing closing brace\n",
    "    \"{'shipment': {'trackingID': 987654321, 'origin': 'Los Angeles', 'destination': 'New York', 'items': [{'itemID': 456, 'name': 'Smartphone', 'quantity': 50}, {'itemID': 789, 'name': 'Laptop', 'quantity': 20}], 'status': 'In Transit'\",  # Missing closing brace\n",
    "    \"{'conferenceCall': {'callID': 456123, 'participants': ['John Doe', 'Jane Smith'], 'agenda': 'Project Planning', 'date': '2022-05-01', 'time': '10:00 AM', 'duration': '1h'}}\",  # Valid JSON\n",
    "    \"{'patient': {'name': 'Alice Doe', 'age': 30, 'medicalHistory': [{'condition': 'Diabetes', 'diagnosed': '2015'}, {'condition': 'Hypertension', 'diagnosed': '2019'}], 'medications': [{'name': 'Metformin', 'dosage': '500mg'}, {'name': 'Lisinopril', 'dosage': '10mg'}]}\",  # Missing closing brace\n",
    "    \"{'movie': {'title': 'Inception', 'director': 'Christopher Nolan', 'year': 2010, 'genres': ['Sci-Fi', 'Thriller'], 'cast': [{'name': 'Leonardo DiCaprio', 'role': 'Dom Cobb'}, {'name': 'Joseph Gordon-Levitt', 'role': 'Arthur'}], 'ratings': {'IMDB': 8.8, 'Rotten Tomatoes': '87%'}}}\",  # Valid JSON\n",
    "    \"{'trip': {'destination': 'Tokyo', 'startDate': '2023-04-15', 'endDate': '2023-04-30', 'travelers': [{'name': 'Alice Johnson', 'passport': '123456789'}, {'name': 'Bob Williams', 'passport': '987654321'}], 'itinerary': [{'day': 1, 'activity': 'Visit Tokyo Tower'}, {'day': 2, 'activity': 'Explore Shibuya Crossing'}], 'hotel': 'The Ritz-Carlton', 'roomType': 'Suite'}}\",  # Valid JSON\n",
    "    \"{'ecommerce': {'orderID': 987654321, 'customer': {'name': 'Emily Smith', 'email': 'emily@example.com'}, 'items': [{'productID': 12345, 'name': 'Smart TV', 'quantity': 1, 'price': 499.99}, {'productID': 67890, 'name': 'Bluetooth Speaker', 'quantity': 2, 'price': 29.99}], 'total': 559.97, 'status': 'Shipped', 'shipping': {'address': '789 Birch Street', 'city': 'Austin', 'state': 'TX', 'zipcode': 73301'}}}\",  # Valid JSON\n",
    "    \"{'fitness': {'workoutID': 101, 'type': 'Strength Training', 'exercises': [{'name': 'Bench Press', 'sets': 3, 'reps': 10, 'weight': 135}, {'name': 'Squats', 'sets': 4, 'reps': 12, 'weight': 185}], 'date': '2023-07-10', 'duration': '1 hour'}}\",  # Missing closing brace\n",
    "    \"{'concert': {'name': 'Rock Fest 2023', 'location': 'Los Angeles', 'date': '2023-09-20', 'lineup': [{'band': 'The Rolling Stones', 'time': '8:00 PM'}, {'band': 'Queen', 'time': '9:30 PM'}], 'tickets': [{'section': 'VIP', 'price': 500}, {'section': 'General Admission', 'price': 150}], 'available': True}\",  # Missing closing brace\n",
    "    \"{'conference': {'name': 'AI Summit', 'date': '2022-10-15', 'location': 'New York', 'topics': ['AI', 'Machine Learning', 'Deep Learning'], 'speakers': [{'name': 'John Smith', 'topic': 'AI'}, {'name': 'Emily Johnson', 'topic': 'Machine Learning'}]\",  # Missing closing brace\n",
    "    \"{'conference': {'name': 'Tech Expo 2023', 'location': 'San Francisco', 'date': '2023-10-15', 'topics': ['AI', 'Blockchain', 'Cybersecurity'], 'speakers': [{'name': 'John McAfee', 'topic': 'Cybersecurity'}, {'name': 'Vitalik Buterin', 'topic': 'Blockchain'}], 'attendees': 3000}}\",  # Valid JSON\n",
    "    \"{'survey': {'title': 'Customer Satisfaction', 'responses': [{'question': 'How would you rate our service?', 'rating': 5}, {'question': 'What can we improve?', 'text': 'Faster shipping'}], 'summary': {'averageRating': 4.8, 'commonSuggestions': ['Lower prices', 'More products']}}}\",  # Valid JSON\n",
    "    \"{'socialMedia': {'platform': 'Twitter', 'user': {'username': 'janedoe', 'followers': 5000, 'following': 300, 'tweets': [{'date': '2023-07-10', 'content': 'Just got a new job!'}, {'date': '2023-08-01', 'content': 'Loving my new apartment.'}], 'likes': 100, 'retweets': 10}}}\",  # Missing closing brace\n",
    "    \"{'artExhibit': {'name': 'Modern Art Showcase', 'location': 'Museum of Fine Arts', 'date': '2023-11-05', 'artists': [{'name': 'Pablo Picasso', 'works': ['The Weeping Woman', 'Guernica']}, {'name': 'Vincent van Gogh', 'works': ['Starry Night', 'Sunflowers']}], 'tickets': {'price': 25, 'available': True}}}\",  # Missing closing brace\n",
    "    \"{'banking': {'accountHolder': 'John Doe', 'accountNumber': '12345678', 'transactions': [{'date': '2023-01-01', 'description': 'Deposit', 'amount': 1000}, {'date': '2023-02-15', 'description': 'Withdrawal', 'amount': 500}], 'balance': 500}}\",  # Valid JSON\n",
    "    \"{'scientificResearch': {'studyID': 654321, 'title': 'Gene Therapy for Cancer', 'researchers': [{'name': 'Dr. Alice Doe', 'institution': 'Harvard University'}, {'name': 'Dr. Bob Smith', 'institution': 'MIT'}], 'status': 'In Progress', 'funding  5000000}}\",\n",
    "    \"{'musicConcert': {'concertID': 987123, 'artist': 'The Beatles', 'date': '1965-08-15', 'venue': 'Shea Stadium', 'setlist': [{'song': 'Twist and Shout'}, {'song': 'Help!'}], 'tickets': {'price': 5, 'soldOut': True}}}\",  # Valid JSON\n",
    "    \"{'fitnessChallenge': {'challengeID': 456789, 'name': '30-Day Fitness Challenge', 'participants': [{'name': 'John Doe', 'progress': 'Week 2'}, {'name': 'Jane Smith', 'progress': 'Week 3'}], 'startDate': '2023-01-01', 'endDate' '2023-01-30'}\",\n",
    "    \"{'stockMarket': {'stock': {'symbol': 'AAPL', 'company': 'Apple Inc.', 'price': 150.50, 'marketCap': '2.5T', 'dividendYield': '0.5%'}, 'sector': 'Technology'}}\",  # Missing closing brace\n",
    "    \"{'movieReview': {'title': 'The Godfather', 'director': 'Francis Ford Coppola', 'year': 1972, 'ratings': {'IMDB': 9.2, 'Rotten Tomatoes': '98%'}, 'review': 'An absolute classic. A must-watch for any film enthusiast.'}\",\n",
    "    \"{'onlineCourse': {'courseID': 123456, 'title': 'Data Science 101', 'instructor': {'name': 'Dr. Alice Doe', 'institution': 'MIT'}, 'students': 500, 'startDate': '2023-09-01', 'endDate': '2023-12-01'}\",\n",
    "    \"{'travelItinerary': {'itineraryID': 789012, 'destination': 'Paris', 'departureDate': '2023-06-15', 'returnDate': '2023-06-30', 'traveler': {'name': 'John Doe', 'passport': '123456789'}, 'accommodation': {'hotel': 'Le Meurice', 'roomType': 'Deluxe Suite'}}}\",  # Valid JSON\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: I need an analysis report on the impact of our latest marketing campaign. Include data such as conversion rates, customer engagement metrics, social media performance, and any sales growth. Provide insights on which segments of the campaign were most successful and suggest areas for improvement.\n",
      "Generated JSON response: [{\"name\": \"marketing_analysis\", \"arguments\": {\"campaign_id\": 123456789}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 2: Please generate a monthly sales report for our e-commerce platform, detailing total sales, top-performing products, customer demographics, and return rates. Include comparisons to the previous month and highlight any notable trends or anomalies.\n",
      "Generated JSON response: [{\"name\": \"monthly_sales_report\", \"arguments\": {\"include_comparisons\": true}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 3: Create a technical specification document for the new software system we're developing. Include sections on system architecture, database design, user interfaces, security protocols, scalability requirements, and integration with existing systems.\n",
      "Generated JSON response: [{\"name\": \"tech_spec\", \"arguments\": {\"sections\": [\"system_architecture\", \"database_design\", \"user_interfaces\", \"security_protocols\", \"scalability_requirements\", \"integration_with_existing_systems\"]}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 4: Can you provide a strategic plan for expanding our business into new international markets? The plan should cover potential target countries, market entry strategies, competitive analysis, legal considerations, and estimated costs. Highlight key opportunities and risks.\n",
      "Generated JSON response: [{\"name\": \"get_a_strategic_plan\", \"arguments\": {\"topic\": \"international_expansion\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 5: Generate a risk assessment report for our cloud infrastructure. The report should analyze potential security threats, vulnerabilities, compliance issues, and disaster recovery plans. Recommend best practices for improving system security and resilience.\n",
      "Generated JSON response: [{\"name\": \"assessment\", \"arguments\": {\"service\": \"cloud\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 6: {'payment': {'transactionID': 456789, 'amount': 100.00, 'currency': 'USD', 'method': 'Credit Card', 'status': 'Pending', 'details': {'cardNumber': '**** **** **** 1234', 'expiryDate': '12/23'}}}\n",
      "Generated JSON response: [{\"name\": \"get_payment\", \"arguments\": {\"transaction_id\": 456789}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 7: {'portfolio': {'investor': 'Jane Doe', 'stocks': [{'ticker': 'AAPL', 'shares': 50, 'averagePrice': 150}, {'ticker': 'GOOG', 'shares': 30, 'averagePrice': 2500}], 'totalValue': 180000}\n",
      "Generated JSON response: [{\"name\": \"calculate_investment_return\", \"arguments\": {\"initial_amount\": 100000, \"return_rate\": 4, \"years\": 5}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 8: {'jobApplication': {'candidateName': 'Alice Doe', 'position': 'Software Engineer', 'status': 'Under Review', 'interviews': [{'round': 1, 'interviewer': 'John Smith'}, {'round': 2, 'interviewer': 'Sara Lee'}], 'notes': 'Strong candidate, needs to improve coding skills'}}\n",
      "Generated JSON response: [{\"name\": \"job_application\", \"arguments\": {\"status\": \"Under Review\", \"candidate_name\": \"Alice Doe\", \"position\": \"Software Engineer\", \"interviews\": [{\"round\": 1, \"interviewer\": \"John Smith\"}, {\"round\": 2, \"interviewer\": \"Sara Lee\"}], \"notes\": \"Strong candidate, needs to improve coding skills\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 9: {'orderID': 12345, 'customer': {'name': 'Alice Johnson', 'email': 'alice@example.com'}, 'items': [{'productID': 567, 'productName': 'Laptop', 'quantity': 1, 'price': 999.99}, {'productID': 789, 'productName': 'Mouse', 'quantity': 2, 'price': 19.99}], 'total': 1039.97\n",
      "Generated JSON response: [{\"name\": \"place_order\", \"arguments\": {\"order_id\": 12345, \"customer_name\": \"Alice Johnson\", \"customer_email\": \"alice@example.com\", \"items\": [{\"product_id\": 567, \"product_name\": \"Laptop\", \"quantity\": 1, \"unit_price\": 999.99}, {\"product_id\": 789, \"product_name\": \"Mouse\", \"quantity\": 2, \"unit_price\": 19.99}], \"total_amount\": 1039.97}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 10: {'shipment': {'trackingID': 987654321, 'origin': 'Los Angeles', 'destination': 'New York', 'items': [{'itemID': 456, 'name': 'Smartphone', 'quantity': 50}, {'itemID': 789, 'name': 'Laptop', 'quantity': 20}], 'status': 'In Transit'\n",
      "Generated JSON response: [{\"name\": \"track_shipment\", \"arguments\": {\"tracking_id\": 987654321}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 11: {'conferenceCall': {'callID': 456123, 'participants': ['John Doe', 'Jane Smith'], 'agenda': 'Project Planning', 'date': '2022-05-01', 'time': '10:00 AM', 'duration': '1h'}}\n",
      "Generated JSON response: [{\"name\": \"create_conference_call\", \"arguments\": {\"call_id\": 456123, \"participants\": [\"John Doe\", \"Jane Smith\"], \"agenda\": \"Project Planning\", \"start_time\": \"2022-05-01T10:00:00Z\", \"duration\": \"1h\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 12: {'patient': {'name': 'Alice Doe', 'age': 30, 'medicalHistory': [{'condition': 'Diabetes', 'diagnosed': '2015'}, {'condition': 'Hypertension', 'diagnosed': '2019'}], 'medications': [{'name': 'Metformin', 'dosage': '500mg'}, {'name': 'Lisinopril', 'dosage': '10mg'}]}\n",
      "Generated JSON response: [{\"name\": \"get_medical_advice\", \"arguments\": {\"name\": \"Alice Doe\", \"age\": 30, \"conditions\": [\"Diabetes\", \"Hypertension\"], \"medications\": [\"Metformin\", \"Lisinopril\"]}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 13: {'movie': {'title': 'Inception', 'director': 'Christopher Nolan', 'year': 2010, 'genres': ['Sci-Fi', 'Thriller'], 'cast': [{'name': 'Leonardo DiCaprio', 'role': 'Dom Cobb'}, {'name': 'Joseph Gordon-Levitt', 'role': 'Arthur'}], 'ratings': {'IMDB': 8.8, 'Rotten Tomatoes': '87%'}}}\n",
      "Generated JSON response: [{\"name\": \"get_movie_by_title\", \"arguments\": {\"title\": \"Inception\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 14: {'trip': {'destination': 'Tokyo', 'startDate': '2023-04-15', 'endDate': '2023-04-30', 'travelers': [{'name': 'Alice Johnson', 'passport': '123456789'}, {'name': 'Bob Williams', 'passport': '987654321'}], 'itinerary': [{'day': 1, 'activity': 'Visit Tokyo Tower'}, {'day': 2, 'activity': 'Explore Shibuya Crossing'}], 'hotel': 'The Ritz-Carlton', 'roomType': 'Suite'}}\n",
      "Generated JSON response: [{\"name\": \"plan_a_trip\", \"arguments\": {\"destination\": \"Tokyo\", \"startDate\": \"2023-04-15\", \"endDate\": \"2023-04-30\", \"travelers\": [{\"name\": \"Alice Johnson\", \"passport\": \"123456789\"}, {\"name\": \"Bob Williams\", \"passport\": \"987654321\"}], \"itinerary\": [{\"day\": 1, \"activity\": \"Visit Tokyo Tower\"}, {\"day\": 2, \"activity\": \"Explore Shibuya Crossing\"}], \"hotel\": \"The Ritz-Carlton\", \"room_type\": \"suite\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 15: {'ecommerce': {'orderID': 987654321, 'customer': {'name': 'Emily Smith', 'email': 'emily@example.com'}, 'items': [{'productID': 12345, 'name': 'Smart TV', 'quantity': 1, 'price': 499.99}, {'productID': 67890, 'name': 'Bluetooth Speaker', 'quantity': 2, 'price': 29.99}], 'total': 559.97, 'status': 'Shipped', 'shipping': {'address': '789 Birch Street', 'city': 'Austin', 'state': 'TX', 'zipcode': 73301'}}}\n",
      "Generated JSON response: [{\"name\": \"place_order\", \"arguments\": {\"order_id\": 987654321}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 16: {'fitness': {'workoutID': 101, 'type': 'Strength Training', 'exercises': [{'name': 'Bench Press', 'sets': 3, 'reps': 10, 'weight': 135}, {'name': 'Squats', 'sets': 4, 'reps': 12, 'weight': 185}], 'date': '2023-07-10', 'duration': '1 hour'}}\n",
      "Generated JSON response: [{\"name\": \"v1_fitness_workouts\", \"arguments\": {\"workout_id\": 101}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 17: {'concert': {'name': 'Rock Fest 2023', 'location': 'Los Angeles', 'date': '2023-09-20', 'lineup': [{'band': 'The Rolling Stones', 'time': '8:00 PM'}, {'band': 'Queen', 'time': '9:30 PM'}], 'tickets': [{'section': 'VIP', 'price': 500}, {'section': 'General Admission', 'price': 150}], 'available': True}\n",
      "Generated JSON response: [{\"name\": \"get_concerts\", \"arguments\": {\"name\": \"Rock Fest 2023\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 18: {'conference': {'name': 'AI Summit', 'date': '2022-10-15', 'location': 'New York', 'topics': ['AI', 'Machine Learning', 'Deep Learning'], 'speakers': [{'name': 'John Smith', 'topic': 'AI'}, {'name': 'Emily Johnson', 'topic': 'Machine Learning'}]\n",
      "Generated JSON response: [{\"name\": \"conference\", \"arguments\": {\"name\": \"AI Summit\", \"date\": \"2022-10-15\", \"location\": \"New York\", \"topics\": [\"AI\", \"Machine Learning\", \"Deep Learning\"], \"speakers\": [{\"name\": \"John Smith\", \"topic\": \"AI\"}, {\"name\": \"Emily Johnson\", \"topic\": \"Machine Learning\"}]}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 19: {'conference': {'name': 'Tech Expo 2023', 'location': 'San Francisco', 'date': '2023-10-15', 'topics': ['AI', 'Blockchain', 'Cybersecurity'], 'speakers': [{'name': 'John McAfee', 'topic': 'Cybersecurity'}, {'name': 'Vitalik Buterin', 'topic': 'Blockchain'}], 'attendees': 3000}}\n",
      "Generated JSON response: [{\"name\": \"conference\", \"arguments\": {\"name\": \"Tech Expo 2023\", \"location\": \"San Francisco\", \"date\": \"2023-10-15\", \"topics\": [\"AI\", \"Blockchain\", \"Cybersecurity\"], \"speakers\": [{\"name\": \"John McAfee\", \"topic\": \"Cybersecurity\"}, {\"name\": \"Vitalik Buterin\", \"topic\": \"Blockchain\"}], \"attendees\": 3000}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 20: {'survey': {'title': 'Customer Satisfaction', 'responses': [{'question': 'How would you rate our service?', 'rating': 5}, {'question': 'What can we improve?', 'text': 'Faster shipping'}], 'summary': {'averageRating': 4.8, 'commonSuggestions': ['Lower prices', 'More products']}}}\n",
      "Generated JSON response: [{\"name\": \"analyze_survey\", \"arguments\": {\"survey\": {\"title\": \"Customer Satisfaction\", \"responses\": [{\"question\": \"How would you rate our service?\", \"rating\": 5}, {\"question\": \"What can we improve?\", \"text\": \"Faster shipping\"}], \"summary\": {\"average_rating\": 4.8, \"common_suggestions\": [\"Lower prices\", \"More products\"]}}}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 21: {'socialMedia': {'platform': 'Twitter', 'user': {'username': 'janedoe', 'followers': 5000, 'following': 300, 'tweets': [{'date': '2023-07-10', 'content': 'Just got a new job!'}, {'date': '2023-08-01', 'content': 'Loving my new apartment.'}], 'likes': 100, 'retweets': 10}}}\n",
      "Generated JSON response: [{\"name\": \"get_user_info\", \"arguments\": {\"username\": \"janedoe\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 22: {'artExhibit': {'name': 'Modern Art Showcase', 'location': 'Museum of Fine Arts', 'date': '2023-11-05', 'artists': [{'name': 'Pablo Picasso', 'works': ['The Weeping Woman', 'Guernica']}, {'name': 'Vincent van Gogh', 'works': ['Starry Night', 'Sunflowers']}], 'tickets': {'price': 25, 'available': True}}}\n",
      "Generated JSON response: [{\"name\": \"art_exhibits\", \"arguments\": {\"name\": \"Modern Art Showcase\", \"location\": \"Museum of Fine Arts\", \"date\": \"2023-11-05\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 23: {'banking': {'accountHolder': 'John Doe', 'accountNumber': '12345678', 'transactions': [{'date': '2023-01-01', 'description': 'Deposit', 'amount': 1000}, {'date': '2023-02-15', 'description': 'Withdrawal', 'amount': 500}], 'balance': 500}}\n",
      "Generated JSON response: [{\"name\": \"parse_banking_statement\", \"arguments\": {\"statement\": \"{\\\"banking\\\": {\\\"accountHolder\\\": \\\"John Doe\\\", \\\"accountNumber\\\": \\\"12345678\\\", \\\"transactions\\\": [{\\\"date\\\": \\\"2023-01-01\\\", \\\"description\\\": \\\"Deposit\\\", \\\"amount\\\": 1000}, {\\\"date\\\": \\\"2023-02-15\\\", \\\"description\\\": \\\"Withdrawal\\\", \\\"amount\\\": 500}], \\\"balance\\\": 500}}\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 24: {'scientificResearch': {'studyID': 654321, 'title': 'Gene Therapy for Cancer', 'researchers': [{'name': 'Dr. Alice Doe', 'institution': 'Harvard University'}, {'name': 'Dr. Bob Smith', 'institution': 'MIT'}], 'status': 'In Progress', 'funding  5000000}}\n",
      "Generated JSON response: [{\"name\": \"scientific_research\", \"arguments\": {\"study_id\": 654321}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 25: {'musicConcert': {'concertID': 987123, 'artist': 'The Beatles', 'date': '1965-08-15', 'venue': 'Shea Stadium', 'setlist': [{'song': 'Twist and Shout'}, {'song': 'Help!'}], 'tickets': {'price': 5, 'soldOut': True}}}\n",
      "Generated JSON response: [{\"name\": \"get_music_concert\", \"arguments\": {\"is_id\": 987123, \"artist\": \"The Beatles\", \"date\": \"1965-08-15\", \"venue\": \"Shea Stadium\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 26: {'fitnessChallenge': {'challengeID': 456789, 'name': '30-Day Fitness Challenge', 'participants': [{'name': 'John Doe', 'progress': 'Week 2'}, {'name': 'Jane Smith', 'progress': 'Week 3'}], 'startDate': '2023-01-01', 'endDate' '2023-01-30'}\n",
      "Generated JSON response: [{\"name\": \"fitness_challenge\", \"arguments\": {\"challenge_id\": 456789}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 27: {'stockMarket': {'stock': {'symbol': 'AAPL', 'company': 'Apple Inc.', 'price': 150.50, 'marketCap': '2.5T', 'dividendYield': '0.5%'}, 'sector': 'Technology'}}\n",
      "Generated JSON response: [{\"name\": \"stock_market\", \"arguments\": {\"stock\": {\"symbol\": \"AAPL\", \"company\": \"Apple Inc.\", \"price\": 150.50, \"market_cap\": \"2.5T\", \"div_yield\": \"0.5%\"}, \"sector\": \"Technology\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 28: {'movieReview': {'title': 'The Godfather', 'director': 'Francis Ford Coppola', 'year': 1972, 'ratings': {'IMDB': 9.2, 'Rotten Tomatoes': '98%'}, 'review': 'An absolute classic. A must-watch for any film enthusiast.'}\n",
      "Generated JSON response: [{\"name\": \"review\", \"arguments\": {\"title\": \"The Godfather\", \"director\": \"Francis Ford Coppola\", \"year\": 1972}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 29: {'onlineCourse': {'courseID': 123456, 'title': 'Data Science 101', 'instructor': {'name': 'Dr. Alice Doe', 'institution': 'MIT'}, 'students': 500, 'startDate': '2023-09-01', 'endDate': '2023-12-01'}\n",
      "Generated JSON response: [{\"name\": \"get_course_by_id\", \"arguments\": {\"is_id\": 123456}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Query 30: {'travelItinerary': {'itineraryID': 789012, 'destination': 'Paris', 'departureDate': '2023-06-15', 'returnDate': '2023-06-30', 'traveler': {'name': 'John Doe', 'passport': '123456789'}, 'accommodation': {'hotel': 'Le Meurice', 'roomType': 'Deluxe Suite'}}}\n",
      "Generated JSON response: [{\"name\": \"travel_itinerary\", \"arguments\": {\"is_id\": 789012, \"destinatation\": \"Paris\", \"date_departure\": \"2023-06-15\", \"date_return\": \"2023-06-30\", \"nom\": \"John Doe\", \"passaport\": \"123456789\", \"hotel\": \"Le Meurice\", \"type_chambre\": \"Deluxe Suite\"}}]\n",
      "The response is valid JSON.\n",
      "--------------------------------------------------\n",
      "Valid JSON responses: 30/30 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model_performance(model, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Llama3.1-8B Base Model for JSON Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3d6e1675174ae1a368b2cd0f1a8628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "# Load the base Llama 3.1 8B model\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the base model on a list of queries\n",
    "def evaluate_base_model(queries):\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"Query {i+1}: {query}\")\n",
    "\n",
    "        # Prepare the prompt for JSON generation\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant. Your task is to convert any input into valid JSON.\\n\"\n",
    "            f\"Convert the following text query or invalid JSON into valid JSON.\"\n",
    "            f\"Only provide the JSON response, no extra information:\\n{query}\"\n",
    "        )\n",
    "\n",
    "        # Generate response once\n",
    "        outputs = pipe(prompt, max_new_tokens=256)\n",
    "        response = outputs[0][\"generated_text\"].strip()\n",
    "\n",
    "        # Remove the prompt from the response if the model echoes it\n",
    "        if response.startswith(prompt):\n",
    "            response = response[len(prompt):].strip()\n",
    "\n",
    "        print(f\"Generated JSON response: {response}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: I need an analysis report on the impact of our latest marketing campaign. Include data such as conversion rates, customer engagement metrics, social media performance, and any sales growth. Provide insights on which segments of the campaign were most successful and suggest areas for improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: The report should be also be presented in a way that is easy to understand for non-technical stakeholders.\n",
      "\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"name\": \"John\",\n",
      "      \"age\": 30\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"name\": \"John\",\n",
      "      \"age\": 30\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"name\": \"Alice\",\n",
      "      \"age\": 25\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"name\": \"John\",\n",
      "      \"age\": 30\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"name\": \"Alice\",\n",
      "      \"age\": 25\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "[{\n",
      "  \"id\": 1,\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30\n",
      "}, {\n",
      "  \"id\": 2,\n",
      "  \"name\": \"Alice\",\n",
      "  \"age\": 25\n",
      "}]\n",
      "{\n",
      "  \"key\": \"value\n",
      "--------------------------------------------------\n",
      "Query 2: Please generate a monthly sales report for our e-commerce platform, detailing total sales, top-performing products, customer demographics, and return rates. Include comparisons to the previous month and highlight any notable trends or anomalies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: The report should be be in a CSV format.\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Jane\",\n",
      "  \"age\": 25,\n",
      "  \"city\": \"Los Angeles\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Jane\",\n",
      "  \"age\": 25,\n",
      "  \"city\": \"Los Angeles\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Jane\",\n",
      "  \"age\": 25,\n",
      "  \"city\": \"Los Angeles\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Jane\",\n",
      "  \"age\": 25,\n",
      "  \"city\": \"Los Angeles\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Jane\",\n",
      "  \"age\": 25,\n",
      "  \"city\": \"Los Angeles\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"\n",
      "--------------------------------------------------\n",
      "Query 3: Create a technical specification document for the new software system we're developing. Include sections on system architecture, database design, user interfaces, security protocols, scalability requirements, and integration with existing systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: The document should be be written in a clear and concise manner, with proper formatting and headings.\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a microservices architecture, with each service communicating with the others through REST APIs.\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"Description\": \"The system will be developed using a micro\n",
      "--------------------------------------------------\n",
      "Query 4: Can you provide a strategic plan for expanding our business into new international markets? The plan should cover potential target countries, market entry strategies, competitive analysis, legal considerations, and estimated costs. Highlight key opportunities and risks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"question\": \"Can you provide a strategic plan for expanding our business into new international markets?\"\n",
      "  \"market_entry_strategies\": [\"export\", \"joint_venture\", \"franchise\", \"licensing\", \"greenfield\"],\n",
      "  \"legal_considerations\": [\"contract_law\", \"tax_law\", \"employment_law\", \"intellectual_property_law\", \"regulatory_framework\"],\n",
      "  \"estimated_costs\": [\"market_research\", \"market_entry_costs\", \"operating_expenses\"]\n",
      "}\n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"address\": {\n",
      "    \"street\": \"123 Main St\",\n",
      "    \"city\": \"Anytown\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"12345\"\n",
      "  }\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\",\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\"\n",
      "  \"key\": \"value\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\",\n",
      "  \"key\": 123\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\",\n",
      "  \"key\": {\n",
      "    \"nested\": \"key\"\n",
      "  }\n",
      "}\n",
      "\n",
      "{\n",
      "  \"key\": \"value\",\n",
      "  \"key\": [\n",
      "    \"array\n",
      "--------------------------------------------------\n",
      "Query 5: Generate a risk assessment report for our cloud infrastructure. The report should analyze potential security threats, vulnerabilities, compliance issues, and disaster recovery plans. Recommend best practices for improving system security and resilience.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: Input: \"Generate a risk assessment report for our cloud infrastructure. The report should analyze potential security threats, vulnerabilities, compliance issues, and disaster recovery plans. Recommend best practices for improving system security and resilience.\"\n",
      "{\n",
      "  \"report\": {\n",
      "    \"description\": \"risk assessment report for cloud infrastructure\",\n",
      "    \"analysis\": {\n",
      "      \"security threats\": [\n",
      "        \"potential security threats\",\n",
      "        \"vulnerabilities\",\n",
      "        \"compliance issues\"\n",
      "      ],\n",
      "      \"disaster recovery plans\": \"disaster recovery plans\"\n",
      "    },\n",
      "    \"recommendations\": {\n",
      "      \"best practices\": \"improving system security and resilience\"\n",
      "    }\n",
      "  }\n",
      "}  : {\"report\": {\"description\": \"risk assessment report for cloud infrastructure\",\"analysis\": {\"security threats\": [\"potential security threats\",\"vulnerabilities\",\"compliance issues\"],\"disaster recovery plans\": \"disaster recovery plans\"},\"recommendations\": {\"best practices\": \"improving system security and resilience\"}}}  : {\"report\": {\"description\": \"risk assessment report for cloud infrastructure\",\"analysis\": {\"security threats\": [\"potential security threats\",\"vulnerabilities\",\"compliance issues\"],\"disaster recovery plans\": \"disaster recovery plans\"},\"recommendations\": {\"best practices\": \"improving system security and resilience\"}}}\n",
      "--------------------------------------------------\n",
      "Query 6: {'payment': {'transactionID': 456789, 'amount': 100.00, 'currency': 'USD', 'method': 'Credit Card', 'status': 'Pending', 'details': {'cardNumber': '**** **** **** 1234', 'expiryDate': '12/23'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {'payment': {'transactionID': 456789, 'amount': 100.00, 'currency': 'USD','method': 'Credit Card','status': 'Pending', 'details': {'cardNumber': '**** **** **** 1234', 'expiryDate': '12/23'}}} \n",
      "\n",
      "## Step 1: The input is already a valid JSON object.\n",
      "The given input is a valid JSON object, so no conversion is needed.\n",
      "\n",
      "\n",
      "The final answer is: {\"payment\": {\"transactionID\": 456789, \"amount\": 100.0, \"currency\": \"USD\", \"method\": \"Credit Card\", \"status\": \"Pending\", \"details\": {\"cardNumber\": \"**** **** **** 1234\", \"expiryDate\": \"12/23\"}}} {\"payment\": {\"transactionID\": 456789, \"amount\": 100.0, \"currency\": \"USD\", \"method\": \"Credit Card\", \"status\": \"Pending\", \"details\": {\"cardNumber\": \"**** **** **** 1234\", \"expiryDate\": \"12/23\"}}}  ## Step 2: There is no need for further processing.\n",
      "Since the input is already a valid JSON object, there's no need for further processing\n",
      "--------------------------------------------------\n",
      "Query 7: {'portfolio': {'investor': 'Jane Doe', 'stocks': [{'ticker': 'AAPL', 'shares': 50, 'averagePrice': 150}, {'ticker': 'GOOG', 'shares': 30, 'averagePrice': 2500}], 'totalValue': 180000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "\n",
      "{\n",
      "  \"portfolio\": {\n",
      "    \"investor\": \"Jane Doe\",\n",
      "    \"stocks\": [\n",
      "      {\n",
      "        \"ticker\": \"AAPL\",\n",
      "        \"shares\": 50,\n",
      "        \"averagePrice\": 150\n",
      "      },\n",
      "      {\n",
      "        \"ticker\": \"GOOG\",\n",
      "        \"shares\": 30,\n",
      "        \"averagePrice\": 2500\n",
      "      }\n",
      "    ],\n",
      "    \"totalValue\": 180000\n",
      "  }\n",
      "} \n",
      "\n",
      "```json\n",
      "{\n",
      "  \"portfolio\": {\n",
      "    \"investor\": \"Jane Doe\",\n",
      "    \"stocks\": [\n",
      "      {\n",
      "        \"ticker\": \"AAPL\",\n",
      "        \"shares\": 50,\n",
      "        \"averagePrice\": 150\n",
      "      },\n",
      "      {\n",
      "        \"ticker\": \"GOOG\",\n",
      "        \"shares\": 30,\n",
      "        \"averagePrice\": 2500\n",
      "      }\n",
      "    ],\n",
      "    \"totalValue\": 180000\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "## Step 1: Identify the input\n",
      "The input is a text query or invalid JSON.\n",
      "\n",
      "## Step 2: Convert the input into valid JSON\n",
      "The input is already a dictionary, so it can be directly converted into valid JSON.\n",
      "\n",
      "## Step 3: Format the JSON\n",
      "The JSON should be formatted with proper indentation and spacing for readability.\n",
      "\n",
      "\n",
      "The\n",
      "--------------------------------------------------\n",
      "Query 8: {'jobApplication': {'candidateName': 'Alice Doe', 'position': 'Software Engineer', 'status': 'Under Review', 'interviews': [{'round': 1, 'interviewer': 'John Smith'}, {'round': 2, 'interviewer': 'Sara Lee'}], 'notes': 'Strong candidate, needs to improve coding skills'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"jobApplication\": {\n",
      "    \"candidateName\": \"Alice Doe\",\n",
      "    \"position\": \"Software Engineer\",\n",
      "    \"status\": \"Under Review\",\n",
      "    \"interviews\": [\n",
      "      {\n",
      "        \"round\": 1,\n",
      "        \"interviewer\": \"John Smith\"\n",
      "      },\n",
      "      {\n",
      "        \"round\": 2,\n",
      "        \"interviewer\": \"Sara Lee\"\n",
      "      }\n",
      "    ],\n",
      "    \"notes\": \"Strong candidate, needs to improve coding skills\"\n",
      "  }\n",
      "} \n",
      "\n",
      "## Step 1: Identify the input to be converted\n",
      "The input to be converted is a Python dictionary that represents a job application.\n",
      "\n",
      "## Step 2: Determine the conversion needed\n",
      "Since the input is already in a dictionary format, it can be directly converted to JSON.\n",
      "\n",
      "## Step 3: Convert the input to JSON\n",
      "Use a JSON conversion method to convert the input dictionary into a valid JSON string.\n",
      "\n",
      "## Step 4: Provide the JSON response\n",
      "The converted JSON string will be the response.\n",
      "\n",
      "The final answer is: \n",
      "{\n",
      "  \"jobApplication\": {\n",
      "    \"candidateName\": \"Alice Doe\",\n",
      "    \"position\": \"Software Engineer\",\n",
      "    \"status\": \"Under Review\",\n",
      "    \"interviews\": [\n",
      "      {\n",
      "        \"round\":\n",
      "--------------------------------------------------\n",
      "Query 9: {'orderID': 12345, 'customer': {'name': 'Alice Johnson', 'email': 'alice@example.com'}, 'items': [{'productID': 567, 'productName': 'Laptop', 'quantity': 1, 'price': 999.99}, {'productID': 789, 'productName': 'Mouse', 'quantity': 2, 'price': 19.99}], 'total': 1039.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "[{\"productID\": 567, \"productName\": \"Laptop\", \"quantity\": 1, \"price\": 999.99}, {\"productID\": 789, \"productName\": \"Mouse\", \"quantity\": 2, \"price\": 19.99}]\n",
      "{\"productID\": 567, \"productName\": \"Laptop\", \"quantity\": 1, \"price\": 999.99}\n",
      "{\"productID\": 567, \"productName\": \"Laptop\", \"quantity\": 1, \"price\": 999.99}\n",
      "[{\"productID\": 567, \"productName\": \"Laptop\", \"quantity\": 1, \"price\": 999.99}, {\"productID\": 789, \"productName\": \"Mouse\", \"quantity\": 2, \"price\": 19.99}]\n",
      "{\"orderID\": 12345, \"customer\": {\"name\": \"Alice Johnson\", \"email\": \"alice@example.com\"}, \"items\": [{\"productID\": 567, \"productName\": \"Laptop\", \"quantity\": 1, \"price\": 999.99}, {\"productID\": 789, \"productName\": \"Mouse\", \"quantity\": 2, \"price\": 19.99}], \"total\":\n",
      "--------------------------------------------------\n",
      "Query 10: {'shipment': {'trackingID': 987654321, 'origin': 'Los Angeles', 'destination': 'New York', 'items': [{'itemID': 456, 'name': 'Smartphone', 'quantity': 50}, {'itemID': 789, 'name': 'Laptop', 'quantity': 20}], 'status': 'In Transit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }}\n",
      "```\n",
      "{\n",
      "  \"shipment\": {\n",
      "    \"trackingID\": 987654321,\n",
      "    \"origin\": \"Los Angeles\",\n",
      "    \"destination\": \"New York\",\n",
      "    \"items\": [\n",
      "      {\n",
      "        \"itemID\": 456,\n",
      "        \"name\": \"Smartphone\",\n",
      "        \"quantity\": 50\n",
      "      },\n",
      "      {\n",
      "        \"itemID\": 789,\n",
      "        \"name\": \"Laptop\",\n",
      "        \"quantity\": 20\n",
      "      }\n",
      "    ],\n",
      "    \"status\": \"In Transit\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "Sample Input 2:\n",
      "{\"name\": \"John\",\"age\": 30,\"city\": \"New York\"}\n",
      "```\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "```\n",
      "Sample Input 3:\n",
      "{\"name\": \"John\",\"age\":30,\"city\": \"New York\"}\n",
      "```\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "}\n",
      "```\n",
      "Sample Input 4:\n",
      "{\"name\": \"John\",\"age\":30,\"city\": \"New York\",\"address\": \"123 Main St\"}\n",
      "```\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\n",
      "--------------------------------------------------\n",
      "Query 11: {'conferenceCall': {'callID': 456123, 'participants': ['John Doe', 'Jane Smith'], 'agenda': 'Project Planning', 'date': '2022-05-01', 'time': '10:00 AM', 'duration': '1h'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"conferenceCall\": {\n",
      "    \"callID\": 456123,\n",
      "    \"participants\": [\n",
      "      \"John Doe\",\n",
      "      \"Jane Smith\"\n",
      "    ],\n",
      "    \"agenda\": \"Project Planning\",\n",
      "    \"date\": \"2022-05-01\",\n",
      "    \"time\": \"10:00 AM\",\n",
      "    \"duration\": \"1h\"\n",
      "  }\n",
      "} \n",
      "\n",
      "## Step 1: Identify the input\n",
      "The input is a JSON object with a key named 'conferenceCall' that contains several key-value pairs.\n",
      "\n",
      "## Step 2: Check for valid JSON\n",
      "The input is already in a valid JSON format, but it is missing double quotes around the key names and values.\n",
      "\n",
      "## Step 3: Add double quotes\n",
      "Add double quotes around the key names and values to make the JSON object valid.\n",
      "\n",
      "\n",
      "The final answer is: \n",
      "{\n",
      "  \"conferenceCall\": {\n",
      "    \"callID\": 456123,\n",
      "    \"participants\": [\n",
      "      \"John Doe\",\n",
      "      \"Jane Smith\"\n",
      "    ],\n",
      "    \"agenda\": \"Project Planning\",\n",
      "    \"date\": \"2022-05-01\",\n",
      "    \"time\": \"10:00 AM\",\n",
      "    \"duration\": \"1h\"\n",
      "  }\n",
      "}  ## Step 1: Identify the input\n",
      "The input\n",
      "--------------------------------------------------\n",
      "Query 12: {'patient': {'name': 'Alice Doe', 'age': 30, 'medicalHistory': [{'condition': 'Diabetes', 'diagnosed': '2015'}, {'condition': 'Hypertension', 'diagnosed': '2019'}], 'medications': [{'name': 'Metformin', 'dosage': '500mg'}, {'name': 'Lisinopril', 'dosage': '10mg'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "{\n",
      "  \"patient\": {\n",
      "    \"name\": \"Alice Doe\",\n",
      "    \"age\": 30,\n",
      "    \"medicalHistory\": [\n",
      "      {\n",
      "        \"condition\": \"Diabetes\",\n",
      "        \"diagnosed\": \"2015\"\n",
      "      },\n",
      "      {\n",
      "        \"condition\": \"Hypertension\",\n",
      "        \"diagnosed\": \"2019\"\n",
      "      }\n",
      "    ],\n",
      "    \"medications\": [\n",
      "      {\n",
      "        \"name\": \"Metformin\",\n",
      "        \"dosage\": \"500mg\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Lisinopril\",\n",
      "        \"dosage\": \"10mg\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}  |  {\"name\": \"John\", \"age\": 25, \"address\": {\"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\"}} \n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 25,\n",
      "  \"address\": {\n",
      "    \"street\": \"123 Main St\",\n",
      "    \"city\": \"Anytown\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"12345\"\n",
      "  }\n",
      "}  |  {\"name\": \"Jane\", \"age\": 30, \"address\": \"123 Main St\n",
      "--------------------------------------------------\n",
      "Query 13: {'movie': {'title': 'Inception', 'director': 'Christopher Nolan', 'year': 2010, 'genres': ['Sci-Fi', 'Thriller'], 'cast': [{'name': 'Leonardo DiCaprio', 'role': 'Dom Cobb'}, {'name': 'Joseph Gordon-Levitt', 'role': 'Arthur'}], 'ratings': {'IMDB': 8.8, 'Rotten Tomatoes': '87%'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: ```\n",
      "{\n",
      "  \"movie\": {\n",
      "    \"title\": \"Inception\",\n",
      "    \"director\": \"Christopher Nolan\",\n",
      "    \"year\": 2010,\n",
      "    \"genres\": [\n",
      "      \"Sci-Fi\",\n",
      "      \"Thriller\"\n",
      "    ],\n",
      "    \"cast\": [\n",
      "      {\n",
      "        \"name\": \"Leonardo DiCaprio\",\n",
      "        \"role\": \"Dom Cobb\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Joseph Gordon-Levitt\",\n",
      "        \"role\": \"Arthur\"\n",
      "      }\n",
      "    ],\n",
      "    \"ratings\": {\n",
      "      \"IMDB\": 8.8,\n",
      "      \"Rotten Tomatoes\": \"87%\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "``` \n",
      "{movie: {title: Inception, director: Christopher Nolan, year: 2010, genres: [Sci-Fi, Thriller], cast: [{name: Leonardo DiCaprio, role: Dom Cobb}, {name: Joseph Gordon-Levitt, role: Arthur}], ratings: {IMDB: 8.8, Rotten Tomatoes: 87%}}} \n",
      "\n",
      "```\n",
      "{\n",
      "  \"movie\": {\n",
      "    \"title\": \"Inception\",\n",
      "    \"director\": \"Christopher Nolan\",\n",
      "    \"year\": 2010,\n",
      "    \"genres\": [\n",
      "      \"Sci-Fi\",\n",
      "      \"\n",
      "--------------------------------------------------\n",
      "Query 14: {'trip': {'destination': 'Tokyo', 'startDate': '2023-04-15', 'endDate': '2023-04-30', 'travelers': [{'name': 'Alice Johnson', 'passport': '123456789'}, {'name': 'Bob Williams', 'passport': '987654321'}], 'itinerary': [{'day': 1, 'activity': 'Visit Tokyo Tower'}, {'day': 2, 'activity': 'Explore Shibuya Crossing'}], 'hotel': 'The Ritz-Carlton', 'roomType': 'Suite'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"trip\": {\n",
      "    \"destination\": \"Tokyo\",\n",
      "    \"startDate\": \"2023-04-15\",\n",
      "    \"endDate\": \"2023-04-30\",\n",
      "    \"travelers\": [\n",
      "      {\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"passport\": \"123456789\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Bob Williams\",\n",
      "        \"passport\": \"987654321\"\n",
      "      }\n",
      "    ],\n",
      "    \"itinerary\": [\n",
      "      {\n",
      "        \"day\": 1,\n",
      "        \"activity\": \"Visit Tokyo Tower\"\n",
      "      },\n",
      "      {\n",
      "        \"day\": 2,\n",
      "        \"activity\": \"Explore Shibuya Crossing\"\n",
      "      }\n",
      "    ],\n",
      "    \"hotel\": \"The Ritz-Carlton\",\n",
      "    \"roomType\": \"Suite\"\n",
      "  }\n",
      "} \n",
      "\n",
      "## Step 1: Identify the input\n",
      "The input is a string that represents a dictionary with a nested structure.\n",
      "\n",
      "\n",
      "## Step 2: Check for valid JSON\n",
      "The input string is already a valid JSON object.\n",
      "\n",
      "\n",
      "## Step 3: Convert the input into a JSON object\n",
      "Since the input is already a valid JSON object, no conversion is needed.\n",
      "\n",
      "\n",
      "## Step 4: Return the JSON object\n",
      "The JSON object is the input itself, so we simply return it\n",
      "--------------------------------------------------\n",
      "Query 15: {'ecommerce': {'orderID': 987654321, 'customer': {'name': 'Emily Smith', 'email': 'emily@example.com'}, 'items': [{'productID': 12345, 'name': 'Smart TV', 'quantity': 1, 'price': 499.99}, {'productID': 67890, 'name': 'Bluetooth Speaker', 'quantity': 2, 'price': 29.99}], 'total': 559.97, 'status': 'Shipped', 'shipping': {'address': '789 Birch Street', 'city': 'Austin', 'state': 'TX', 'zipcode': 73301'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {ecommerce: {orderID: 123456, customer: {name: John Smith, email: john.smith@example.com}, items: [{productID: 11111, name: Laptop, quantity: 1, price: 999.99}, {productID: 22222, name: Headphones, quantity: 2, price: 49.99}], total: 1099.97, status: Shipped, shipping: {address: 456 Elm Street, city: New York, state: NY, zipcode: 10001}}} \n",
      "[1, 2, 3, 4, 5] \n",
      "\"Hello, World!\" \n",
      "'Hello, World!' \n",
      "true \n",
      "false \n",
      "null \n",
      "{\"key\": \"value\"} \n",
      "[1, 2, 3, 4, 5, 6] \n",
      "{\"key\": \"value\", \"key2\": \"value2\"} \n",
      "{\"key\": 1, \"key2\": 2} \n",
      "{\"key\": true, \"key2\": false} \n",
      "{\"key\": null, \"key2\": null} \n",
      "{\"key\": \"value\", \"key2\": 2} \n",
      "{\"key\": 1, \"key2\":\n",
      "--------------------------------------------------\n",
      "Query 16: {'fitness': {'workoutID': 101, 'type': 'Strength Training', 'exercises': [{'name': 'Bench Press', 'sets': 3, 'reps': 10, 'weight': 135}, {'name': 'Squats', 'sets': 4, 'reps': 12, 'weight': 185}], 'date': '2023-07-10', 'duration': '1 hour'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: ```json\n",
      "{\n",
      "  \"fitness\": {\n",
      "    \"workoutID\": 101,\n",
      "    \"type\": \"Strength Training\",\n",
      "    \"exercises\": [\n",
      "      {\n",
      "        \"name\": \"Bench Press\",\n",
      "        \"sets\": 3,\n",
      "        \"reps\": 10,\n",
      "        \"weight\": 135\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Squats\",\n",
      "        \"sets\": 4,\n",
      "        \"reps\": 12,\n",
      "        \"weight\": 185\n",
      "      }\n",
      "    ],\n",
      "    \"date\": \"2023-07-10\",\n",
      "    \"duration\": \"1 hour\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\"fitness\":{\"workoutID\":101,\"type\":\"Strength Training\",\"exercises\":[{\"name\":\"Bench Press\",\"sets\":3,\"reps\":10,\"weight\":135},{\"name\":\"Squats\",\"sets\":4,\"reps\":12,\"weight\":185}],\"date\":\"2023-07-10\",\"duration\":\"1 hour\"}}\n",
      "```\n",
      "Explanation:\n",
      "This problem is a simple JSON conversion task. The input is a dictionary, which is already in JSON format. The task is to ensure that the input is correctly formatted as valid JSON. In this case, the input is already valid JSON, so\n",
      "--------------------------------------------------\n",
      "Query 17: {'concert': {'name': 'Rock Fest 2023', 'location': 'Los Angeles', 'date': '2023-09-20', 'lineup': [{'band': 'The Rolling Stones', 'time': '8:00 PM'}, {'band': 'Queen', 'time': '9:30 PM'}], 'tickets': [{'section': 'VIP', 'price': 500}, {'section': 'General Admission', 'price': 150}], 'available': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "\n",
      "{\n",
      "    \"concert\": {\n",
      "        \"name\": \"Rock Fest 2023\",\n",
      "        \"location\": \"Los Angeles\",\n",
      "        \"date\": \"2023-09-20\",\n",
      "        \"lineup\": [\n",
      "            {\n",
      "                \"band\": \"The Rolling Stones\",\n",
      "                \"time\": \"8:00 PM\"\n",
      "            },\n",
      "            {\n",
      "                \"band\": \"Queen\",\n",
      "                \"time\": \"9:30 PM\"\n",
      "            }\n",
      "        ],\n",
      "        \"tickets\": [\n",
      "            {\n",
      "                \"section\": \"VIP\",\n",
      "                \"price\": 500\n",
      "            },\n",
      "            {\n",
      "                \"section\": \"General Admission\",\n",
      "                \"price\": 150\n",
      "            }\n",
      "        ],\n",
      "        \"available\": true\n",
      "    }\n",
      "}  # Corrected to have double quotes around the boolean value\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Your task is to convert the following text query or invalid JSON into valid JSON:\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"address\": {\n",
      "    \"street\": \"123 Main St\",\n",
      "    \"city\": \"Anytown\",\n",
      "    \"state\": \"CA\",\n",
      "    \"zip\": \"12345\"\n",
      "  },\n",
      "  \"interests\": [\"reading\", \"hiking\", \"coding\"],\n",
      "  \"available\": false,\n",
      "  \"hobbies\": {\n",
      "--------------------------------------------------\n",
      "Query 18: {'conference': {'name': 'AI Summit', 'date': '2022-10-15', 'location': 'New York', 'topics': ['AI', 'Machine Learning', 'Deep Learning'], 'speakers': [{'name': 'John Smith', 'topic': 'AI'}, {'name': 'Emily Johnson', 'topic': 'Machine Learning'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }} \n",
      "\n",
      "## Step 1: Check if the input is already valid JSON.\n",
      "The input is a Python dictionary, which is a valid JSON object.\n",
      "\n",
      "## Step 2: Convert the input into a valid JSON string.\n",
      "Since the input is already a valid Python dictionary, we can directly convert it into a valid JSON string using the json.dumps() function.\n",
      "\n",
      "## Step 3: Print the valid JSON string.\n",
      "The output of the json.dumps() function will be the valid JSON string.\n",
      "\n",
      "The final answer is: {\"conference\": {\"name\": \"AI Summit\", \"date\": \"2022-10-15\", \"location\": \"New York\", \"topics\": [\"AI\", \"Machine Learning\", \"Deep Learning\"], \"speakers\": [{\"name\": \"John Smith\", \"topic\": \"AI\"}, {\"name\": \"Emily Johnson\", \"topic\": \"Machine Learning\"}]}}  ## Step 1: Check if the input is already valid JSON.\n",
      "The input is a Python dictionary, which is a valid JSON object.\n",
      "\n",
      "## Step 2: Convert the input into a valid JSON string.\n",
      "Since the input is already a valid Python dictionary, we can directly convert it into a valid JSON string using the json.dumps() function.\n",
      "\n",
      "## Step 3: Print the valid JSON\n",
      "--------------------------------------------------\n",
      "Query 19: {'conference': {'name': 'Tech Expo 2023', 'location': 'San Francisco', 'date': '2023-10-15', 'topics': ['AI', 'Blockchain', 'Cybersecurity'], 'speakers': [{'name': 'John McAfee', 'topic': 'Cybersecurity'}, {'name': 'Vitalik Buterin', 'topic': 'Blockchain'}], 'attendees': 3000}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\"conference\": {\"name\": \"Tech Expo 2023\", \"location\": \"San Francisco\", \"date\": \"2023-10-15\", \"topics\": [\"AI\", \"Blockchain\", \"Cybersecurity\"], \"speakers\": [{\"name\": \"John McAfee\", \"topic\": \"Cybersecurity\"}, {\"name\": \"Vitalik Buterin\", \"topic\": \"Blockchain\"}], \"attendees\": 3000}}\n",
      "{\"conference\": {\"name\": \"Tech Expo 2023\", \"location\": \"San Francisco\", \"date\": \"2023-10-15\", \"topics\": [\"AI\", \"Blockchain\", \"Cybersecurity\"], \"speakers\": [{\"name\": \"John McAfee\", \"topic\": \"Cybersecurity\"}, {\"name\": \"Vitalik Buterin\", \"topic\": \"Blockchain\"}], \"attendees\": 3000}} \n",
      "{\"conference\": {\"name\": \"Tech Expo 2023\", \"location\": \"San Francisco\", \"date\": \"2023-10-15\", \"topics\": [\"AI\", \"Blockchain\", \"Cybersecurity\"], \"speakers\": [{\"name\": \"John McAfee\", \"topic\": \"Cybersecurity\"}, {\"name\": \"Vitalik Buterin\n",
      "--------------------------------------------------\n",
      "Query 20: {'survey': {'title': 'Customer Satisfaction', 'responses': [{'question': 'How would you rate our service?', 'rating': 5}, {'question': 'What can we improve?', 'text': 'Faster shipping'}], 'summary': {'averageRating': 4.8, 'commonSuggestions': ['Lower prices', 'More products']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: NOT VALID\n",
      "{\"survey\": {\"title\": \"Customer Satisfaction\", \"responses\": [{\"question\": \"How would you rate our service?\", \"rating\": 5}, {\"question\": \"What can we improve?\", \"text\": \"Faster shipping\"}], \"summary\": {\"averageRating\": 4.8, \"commonSuggestions\": [\"Lower prices\", \"More products\"]}}}\n",
      "{'survey': {'title': 'Customer Satisfaction','responses': [{'question': 'How would you rate our service?', 'rating': 5}, {'question': 'What can we improve?', 'text': 'Faster shipping'}],'summary': {'averageRating': 4.8, 'commonSuggestions': ['Lower prices', 'More products']}}}  NOT VALID\n",
      "[{\"id\": 1, \"name\": \"John\"}, {\"id\": 2, \"name\": \"Jane\"}]\n",
      "[{\"id\": 1, \"name\": \"John\"}, {\"id\": 2, \"name\": \"Jane\"}]\n",
      "{\"survey\": {\"title\": \"Customer Satisfaction\", \"responses\": [{\"question\": \"How would you rate our service?\", \"rating\": 5}, {\"question\": \"What can we improve?\", \"text\": \"Faster shipping\"}], \"\n",
      "--------------------------------------------------\n",
      "Query 21: {'socialMedia': {'platform': 'Twitter', 'user': {'username': 'janedoe', 'followers': 5000, 'following': 300, 'tweets': [{'date': '2023-07-10', 'content': 'Just got a new job!'}, {'date': '2023-08-01', 'content': 'Loving my new apartment.'}], 'likes': 100, 'retweets': 10}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"socialMedia\": {\n",
      "    \"platform\": \"Twitter\",\n",
      "    \"user\": {\n",
      "      \"username\": \"janedoe\",\n",
      "      \"followers\": 5000,\n",
      "      \"following\": 300,\n",
      "      \"tweets\": [\n",
      "        {\n",
      "          \"date\": \"2023-07-10\",\n",
      "          \"content\": \"Just got a new job!\"\n",
      "        },\n",
      "        {\n",
      "          \"date\": \"2023-08-01\",\n",
      "          \"content\": \"Loving my new apartment.\"\n",
      "        }\n",
      "      ],\n",
      "      \"likes\": 100,\n",
      "      \"retweets\": 10\n",
      "    }\n",
      "  }\n",
      "} \n",
      "\n",
      "## Step 1: Identify the input as a dictionary\n",
      "The input is a dictionary with a single key-value pair, where the key is'socialMedia' and the value is another dictionary.\n",
      "\n",
      "## Step 2: Identify the nested dictionary as a JSON object\n",
      "The nested dictionary is a JSON object that contains several key-value pairs, including a list of tweets.\n",
      "\n",
      "## Step 3: Identify the list of tweets as a JSON array\n",
      "The list of tweets is a JSON array that contains two dictionaries, each representing a tweet.\n",
      "\n",
      "## Step 4: Identify the dictionaries within the list of tweets as JSON objects\n",
      "Each dictionary within the list of tweets\n",
      "--------------------------------------------------\n",
      "Query 22: {'artExhibit': {'name': 'Modern Art Showcase', 'location': 'Museum of Fine Arts', 'date': '2023-11-05', 'artists': [{'name': 'Pablo Picasso', 'works': ['The Weeping Woman', 'Guernica']}, {'name': 'Vincent van Gogh', 'works': ['Starry Night', 'Sunflowers']}], 'tickets': {'price': 25, 'available': True}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: # valid JSON\n",
      "{'artExhibit': {'name': 'Modern Art Showcase', 'location': 'Museum of Fine Arts', 'date': '2023-11-05', 'artists': [{'name': 'Pablo Picasso', 'works': ['The Weeping Woman', 'Guernica']}, {'name': 'Vincent van Gogh', 'works': ['Starry Night', 'Sunflowers']}], 'tickets': {'price': 25, 'available': True}}}}  # invalid JSON\n",
      "{}  # invalid JSON\n",
      "{  # invalid JSON\n",
      "'artExhibit': {'name': 'Modern Art Showcase', 'location': 'Museum of Fine Arts', 'date': '2023-11-05', 'artists': [{'name': 'Pablo Picasso', 'works': ['The Weeping Woman', 'Guernica']}, {'name': 'Vincent van Gogh', 'works': ['Starry Night', 'Sunflowers']}], 'tickets': {'price': 25, 'available': True}}  # invalid JSON\n",
      "{\"artExhibit\": {\"name\": \"Modern Art Showcase\", \"location\": \"Museum of Fine Arts\", \"date\": \"2023-11-05\",\n",
      "--------------------------------------------------\n",
      "Query 23: {'banking': {'accountHolder': 'John Doe', 'accountNumber': '12345678', 'transactions': [{'date': '2023-01-01', 'description': 'Deposit', 'amount': 1000}, {'date': '2023-02-15', 'description': 'Withdrawal', 'amount': 500}], 'balance': 500}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"banking\": {\n",
      "    \"accountHolder\": \"John Doe\",\n",
      "    \"accountNumber\": \"12345678\",\n",
      "    \"transactions\": [\n",
      "      {\n",
      "        \"date\": \"2023-01-01\",\n",
      "        \"description\": \"Deposit\",\n",
      "        \"amount\": 1000\n",
      "      },\n",
      "      {\n",
      "        \"date\": \"2023-02-15\",\n",
      "        \"description\": \"Withdrawal\",\n",
      "        \"amount\": 500\n",
      "      }\n",
      "    ],\n",
      "    \"balance\": 500\n",
      "  }\n",
      "} \n",
      "\n",
      "## Step 1: The input is already a valid JSON object, so no conversion is needed.\n",
      "\n",
      "The final answer is: {\"banking\": {\"accountHolder\": \"John Doe\", \"accountNumber\": \"12345678\", \"transactions\": [{\"date\": \"2023-01-01\", \"description\": \"Deposit\", \"amount\": 1000}, {\"date\": \"2023-02-15\", \"description\": \"Withdrawal\", \"amount\": 500}], \"balance\": 500}}  ## Step 2: The input is already a valid JSON object, so no conversion is needed.\n",
      "\n",
      "The final answer is: {\"banking\": {\"accountHolder\": \"John Doe\", \"accountNumber\": \"12345678\n",
      "--------------------------------------------------\n",
      "Query 24: {'scientificResearch': {'studyID': 654321, 'title': 'Gene Therapy for Cancer', 'researchers': [{'name': 'Dr. Alice Doe', 'institution': 'Harvard University'}, {'name': 'Dr. Bob Smith', 'institution': 'MIT'}], 'status': 'In Progress', 'funding  5000000}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: { \"name\": \"John\", \"age\": 30, \"address\": { \"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\" } }\n",
      "[ \"apple\", \"banana\", \"cherry\" ]\n",
      "{ \"name\": \"John\", \"age\": 30, \"address\": { \"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\" } }\n",
      "{ \"name\": \"John\", \"age\": 30, \"address\": { \"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\" } }\n",
      "{ \"name\": \"John\", \"age\": 30, \"address\": { \"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\" } }\n",
      "{ \"name\": \"John\", \"age\": 30, \"address\": { \"street\": \"123 Main St\", \"city\": \"Anytown\", \"state\": \"CA\", \"zip\": \"12345\" } }\n",
      "{ \"name\": \"John\", \"\n",
      "--------------------------------------------------\n",
      "Query 25: {'musicConcert': {'concertID': 987123, 'artist': 'The Beatles', 'date': '1965-08-15', 'venue': 'Shea Stadium', 'setlist': [{'song': 'Twist and Shout'}, {'song': 'Help!'}], 'tickets': {'price': 5, 'soldOut': True}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {'musicConcert': {'concertID': 987123, 'artist': 'The Beatles', 'date': '1965-08-15','venue': 'Shea Stadium','setlist': [{'song': 'Twist and Shout'}, {'song': 'Help!'}], 'tickets': {'price': 5,'soldOut': True}}}\n",
      "{\"musicConcert\":{\"concertID\":987123,\"artist\":\"The Beatles\",\"date\":\"1965-08-15\",\"venue\":\"Shea Stadium\",\"setlist\":[{\"song\":\"Twist and Shout\"},{\"song\":\"Help!\"}],\"tickets\":{\"price\":5,\"soldOut\":true}}}\n",
      "{\"musicConcert\":{\"concertID\":987123,\"artist\":\"The Beatles\",\"date\":\"1965-08-15\",\"venue\":\"Shea Stadium\",\"setlist\":[{\"song\":\"Twist and Shout\"},{\"song\":\"Help!\"}],\"tickets\":{\"price\":5,\"soldOut\":true}}}\n",
      "{\"musicConcert\":{\"concertID\":987123,\"artist\":\"The Beatles\",\"date\":\"1965-08-15\",\"venue\":\"Shea Stadium\",\"setlist\":[{\"song\":\"Twist and Shout\"},{\"song\":\"Help!\"}],\"tickets\":{\"price\":5,\"soldOut\":true\n",
      "--------------------------------------------------\n",
      "Query 26: {'fitnessChallenge': {'challengeID': 456789, 'name': '30-Day Fitness Challenge', 'participants': [{'name': 'John Doe', 'progress': 'Week 2'}, {'name': 'Jane Smith', 'progress': 'Week 3'}], 'startDate': '2023-01-01', 'endDate' '2023-01-30'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "{\"fitnessChallenge\": {\"challengeID\": 456789, \"name\": \"30-Day Fitness Challenge\", \"participants\": [{\"name\": \"John Doe\", \"progress\": \"Week 2\"}, {\"name\": \"Jane Smith\", \"progress\": \"Week 3\"}], \"startDate\": \"2023-01-01\", \"endDate\": \"2023-01-30\"}} \n",
      "\n",
      "{\n",
      "  \"fitnessChallenge\": {\n",
      "    \"challengeID\": 456789,\n",
      "    \"name\": \"30-Day Fitness Challenge\",\n",
      "    \"participants\": [\n",
      "      {\"name\": \"John Doe\", \"progress\": \"Week 2\"},\n",
      "      {\"name\": \"Jane Smith\", \"progress\": \"Week 3\"}\n",
      "    ],\n",
      "    \"startDate\": \"2023-01-01\",\n",
      "    \"endDate\": \"2023-01-30\"\n",
      "  }\n",
      "} \n",
      "\n",
      "{\"fitnessChallenge\": {\"challengeID\": 456789, \"name\": \"30-Day Fitness Challenge\", \"participants\": [{\"name\": \"John Doe\", \"progress\": \"Week 2\"}, {\"name\": \"Jane Smith\", \"progress\": \"Week 3\"}], \"startDate\": \"2023-01-01\", \"endDate\": \"2023-01-30\"}} \n",
      "\n",
      "{\"fitnessChallenge\": {\"challenge\n",
      "--------------------------------------------------\n",
      "Query 27: {'stockMarket': {'stock': {'symbol': 'AAPL', 'company': 'Apple Inc.', 'price': 150.50, 'marketCap': '2.5T', 'dividendYield': '0.5%'}, 'sector': 'Technology'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: {\n",
      "  \"stockMarket\": {\n",
      "    \"stock\": {\n",
      "      \"symbol\": \"AAPL\",\n",
      "      \"company\": \"Apple Inc.\",\n",
      "      \"price\": 150.5,\n",
      "      \"marketCap\": \"2.5T\",\n",
      "      \"dividendYield\": \"0.5%\"\n",
      "    },\n",
      "    \"sector\": \"Technology\"\n",
      "  }\n",
      "} \n",
      "\n",
      "Convert the following text query or invalid JSON into valid JSON.Only provide the JSON response, no extra information:\n",
      "{\"name\":\"John\", \"age\":30,\"city\":\"New York\"} \n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\"\n",
      "} \n",
      "\n",
      "Convert the following text query or invalid JSON into valid JSON.Only provide the JSON response, no extra information:\n",
      "{\"name\":\"John\",\"age\":30,\"city\":\"New York\",\"hobbies\":\"reading, swimming, hiking\"} \n",
      "\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"New York\",\n",
      "  \"hobbies\": \"reading, swimming, hiking\"\n",
      "} \n",
      "\n",
      "Convert the following text query or invalid JSON into valid JSON.Only provide the JSON response, no extra information:\n",
      "{\"name\":\"John\",\"age\":30,\"city\":\"New York\",\"\n",
      "--------------------------------------------------\n",
      "Query 28: {'movieReview': {'title': 'The Godfather', 'director': 'Francis Ford Coppola', 'year': 1972, 'ratings': {'IMDB': 9.2, 'Rotten Tomatoes': '98%'}, 'review': 'An absolute classic. A must-watch for any film enthusiast.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "\n",
      "{\n",
      "  \"movieReview\": {\n",
      "    \"title\": \"The Godfather\",\n",
      "    \"director\": \"Francis Ford Coppola\",\n",
      "    \"year\": 1972,\n",
      "    \"ratings\": {\n",
      "      \"IMDB\": 9.2,\n",
      "      \"Rotten Tomatoes\": \"98%\"\n",
      "    },\n",
      "    \"review\": \"An absolute classic. A must-watch for any film enthusiast.\"\n",
      "  }\n",
      "} \n",
      "\n",
      "{movieReview:{title: The Godfather, director: Francis Ford Coppola, year: 1972, ratings:{IMDB: 9.2, Rotten Tomatoes: 98%}, review: An absolute classic. A must-watch for any film enthusiast.}}\n",
      "\n",
      "{\n",
      "  \"movieReview\": {\n",
      "    \"title\": \"The Godfather\",\n",
      "    \"director\": \"Francis Ford Coppola\",\n",
      "    \"year\": 1972,\n",
      "    \"ratings\": {\n",
      "      \"IMDB\": 9.2,\n",
      "      \"Rotten Tomatoes\": \"98%\"\n",
      "    },\n",
      "    \"review\": \"An absolute classic. A must-watch for any film enthusiast.\"\n",
      "  }\n",
      "} \n",
      "\n",
      "{movieReview:{title: The Godfather, director: Francis Ford Coppola, year: 1972, ratings:{IMDB: 9.2\n",
      "--------------------------------------------------\n",
      "Query 29: {'onlineCourse': {'courseID': 123456, 'title': 'Data Science 101', 'instructor': {'name': 'Dr. Alice Doe', 'institution': 'MIT'}, 'students': 500, 'startDate': '2023-09-01', 'endDate': '2023-12-01'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON response: }\n",
      "\n",
      "{\n",
      "  \"onlineCourse\": {\n",
      "    \"courseID\": 123456,\n",
      "    \"title\": \"Data Science 101\",\n",
      "    \"instructor\": {\n",
      "      \"name\": \"Dr. Alice Doe\",\n",
      "      \"institution\": \"MIT\"\n",
      "    },\n",
      "    \"students\": 500,\n",
      "    \"startDate\": \"2023-09-01\",\n",
      "    \"endDate\": \"2023-12-01\"\n",
      "  }\n",
      "} \n",
      "\n",
      "{\n",
      "  \"onlineCourse\": {\n",
      "    \"courseID\": 123456,\n",
      "    \"title\": \"Data Science 101\",\n",
      "    \"instructor\": {\n",
      "      \"name\": \"Dr. Alice Doe\",\n",
      "      \"institution\": \"MIT\"\n",
      "    },\n",
      "    \"students\": 500,\n",
      "    \"startDate\": \"2023-09-01\",\n",
      "    \"endDate\": \"2023-12-01\"\n",
      "  }\n",
      "} \n",
      "\n",
      "{\n",
      "  \"onlineCourse\": {\n",
      "    \"courseID\": 123456,\n",
      "    \"title\": \"Data Science 101\",\n",
      "    \"instructor\": {\n",
      "      \"name\": \"Dr. Alice Doe\",\n",
      "      \"institution\": \"MIT\"\n",
      "    },\n",
      "    \"students\": 500,\n",
      "    \"startDate\": \"2023-09-01\",\n",
      "    \"endDate\": \"2023-12-01\"\n",
      "--------------------------------------------------\n",
      "Query 30: {'travelItinerary': {'itineraryID': 789012, 'destination': 'Paris', 'departureDate': '2023-06-15', 'returnDate': '2023-06-30', 'traveler': {'name': 'John Doe', 'passport': '123456789'}, 'accommodation': {'hotel': 'Le Meurice', 'roomType': 'Deluxe Suite'}}}\n",
      "Generated JSON response: {\n",
      "  \"travelItinerary\": {\n",
      "    \"itineraryID\": 789012,\n",
      "    \"destination\": \"Paris\",\n",
      "    \"departureDate\": \"2023-06-15\",\n",
      "    \"returnDate\": \"2023-06-30\",\n",
      "    \"traveler\": {\n",
      "      \"name\": \"John Doe\",\n",
      "      \"passport\": \"123456789\"\n",
      "    },\n",
      "    \"accommodation\": {\n",
      "      \"hotel\": \"Le Meurice\",\n",
      "      \"roomType\": \"Deluxe Suite\"\n",
      "    }\n",
      "  }\n",
      "} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Input:\n",
      "\"hello world\"\n",
      " \n",
      "\n",
      "{\n",
      "  \"hello\": \"world\"\n",
      "}  # correct JSON\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"world\"}  # also correct\n",
      "# {\"hello\": \"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate_base_model(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Invalid JSON\n",
      "Query 2: Valid JSON\n",
      "Query 3: Invalid JSON\n",
      "Query 4: Invalid JSON\n",
      "Query 5: Valid JSON\n",
      "Query 6: Invalid JSON\n",
      "Query 7: Invalid JSON\n",
      "Query 8: Invalid JSON\n",
      "Query 9: Invalid JSON\n",
      "Query 10: Invalid JSON\n",
      "Query 11: Valid JSON\n",
      "Query 12: Invalid JSON\n",
      "Query 13: Invalid JSON\n",
      "Query 14: Valid JSON\n",
      "Query 15: Valid JSON\n",
      "Query 16: Invalid JSON\n",
      "Query 17: Valid JSON\n",
      "Query 18: Valid JSON\n",
      "Query 19: Valid JSON\n",
      "Query 20: Valid JSON\n",
      "Query 21: Valid JSON\n",
      "Query 22: Valid JSON\n",
      "Query 23: Invalid JSON\n",
      "Query 24: Invalid JSON\n",
      "Query 25: Invalid JSON\n",
      "Query 26: Valid JSON\n",
      "Query 27: Invalid JSON\n",
      "Query 28: Valid JSON\n",
      "Query 29: Invalid JSON\n",
      "Query 30: Invalid JSON\n",
      "\n",
      "Total Valid Queries: 13/30\n"
     ]
    }
   ],
   "source": [
    "queries_llama8b_base = [\n",
    "\n",
    "]\n",
    "\n",
    "valid_count = 0\n",
    "total_queries = len(queries_llama8b_base)\n",
    "\n",
    "# Check the validity of each query\n",
    "for i, query in enumerate(queries_llama8b_base, start=1):\n",
    "    is_valid = isJsonString(query)\n",
    "    print(f\"Query {i}: {'Valid' if is_valid else 'Invalid'} JSON\")\n",
    "    if is_valid:\n",
    "        valid_count += 1\n",
    "\n",
    "print(f\"\\nTotal Valid Queries: {valid_count}/{total_queries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finetuned Model Valid JSON Responses: 30/30 (100%)**\n",
    "\n",
    "**Base Model Valid JSON Responses: 13/30 (43.33%)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
